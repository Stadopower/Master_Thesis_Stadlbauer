{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-16T10:19:31.294267Z",
     "start_time": "2025-07-16T10:19:30.609235Z"
    }
   },
   "source": [
    "#Spliting train and test correctly (GPT)\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import pyxdf\n",
    "import pandas as pd\n",
    "import re\n",
    "import mne\n",
    "from sklearn.decomposition import fastica\n",
    "from pyprep import PrepPipeline, NoisyChannels\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import matplotlib\n",
    "from mne_icalabel import label_components\n",
    "from autoreject import AutoReject\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, KFold\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib qt\n",
    "matplotlib.use('Qt5Agg')\n",
    "mne.set_log_level('warning')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T10:19:32.267523Z",
     "start_time": "2025-07-16T10:19:32.243952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# some function to make the end result more readable:\n",
    "#filename has to be the entire path to the file so \"data//P101//filename\"\n",
    "\n",
    "def get_data(filename, pilot=False):    # Pilot = True for all pilots except Pilot117\n",
    "    print('Reading data')\n",
    "\n",
    "    # Because of the software switch there are now 3 ACC channels and one Marker channel\n",
    "    nr_non_eeg = 4\n",
    "    if pilot:\n",
    "        nr_non_eeg = 3\n",
    "\n",
    "    # Reading in the xdf files and extracting the marker and eeg streams\n",
    "    streams, fileheader = pyxdf.load_xdf(filename, select_streams=[{'type': 'EEG'}, {'name':'LSL4Unity.OmnideckWaiterVR'}] , synchronize_clocks=False)\n",
    "    marker_stream = next(s for s in streams if 'LSL4Unity.OmnideckWaiterVR' in s['info']['name'][0])\n",
    "    eeg_stream = next(s for s in streams if \"EEG\" in s['info']['type'][0])\n",
    "    eeg_data = np.array(eeg_stream['time_series']).T\n",
    "    #eeg_timestamps = np.array(eeg_stream['time_stamps'])\n",
    "    sfreq = float(eeg_stream['info']['nominal_srate'][0])\n",
    "\n",
    "    # Collection all ch names and renaming TP9, TP10\n",
    "    ch_names = []\n",
    "    for ch in eeg_stream['info']['desc'][0]['channels'][0]['channel']:\n",
    "        if ch['label'][0] == 'TP10':\n",
    "            ch_names.append('FCz')\n",
    "        elif ch['label'][0] == 'TP9':\n",
    "            ch_names.append('Fpz')\n",
    "        elif ch['label'][0] == 'FPz':\n",
    "            ch_names.append('Fpz')\n",
    "        else:\n",
    "            ch_names.append(ch['label'][0])\n",
    "    info = mne.create_info(\n",
    "        ch_names=ch_names[:-nr_non_eeg],\n",
    "        sfreq=sfreq,\n",
    "        ch_types='eeg'\n",
    "    )\n",
    "    raw = mne.io.RawArray(eeg_data[:-nr_non_eeg]/10e5, info)\n",
    "\n",
    "    # Creating the Montage\n",
    "    montage = mne.channels.make_standard_montage('standard_1020')\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    # Calculating the event samples for the annotations\n",
    "    event_samples = (marker_stream['time_stamps'] - eeg_stream['time_stamps'][0])*sfreq\n",
    "    event_samples = event_samples.astype(int)\n",
    "    event_labels = [int(marker[0]) for marker in marker_stream['time_series']]\n",
    "\n",
    "\n",
    "    annotations = mne.Annotations(onset=event_samples / sfreq,\n",
    "                                  duration=[0] * len(event_samples),  # Instantaneous events\n",
    "                                  description=list(event_labels))\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    return raw, marker_stream, event_samples\n",
    "\n",
    "#apply a notch filter at 50hz and filter between 0.01 and 40Hz. Filter above 1Hz is applied when creating the epochs\n",
    "def filter_data(raw):\n",
    "    # Notch Filter at 50 Hz\n",
    "    raw = raw.notch_filter(50, method='fir', phase='zero',verbose=False)\n",
    "    # Filter data between 0.01 and 40 Hz\n",
    "    iir_params = dict(order=2, ftype='butter',verbose=False)\n",
    "    raw = raw.filter(l_freq=0.01, h_freq=40, method='iir', iir_params=iir_params, phase='zero', verbose=False)\n",
    "    return raw\n",
    "\n",
    "\n",
    "# making epochs around a specified marker, Applying 1Hz Highpass filter if epoch is used for ICA\n",
    "def get_epochs(raw: mne.io.Raw, marker_stream, event_samples , marker_id:int, tmin:int, tmax:int, preload=False, ica=True):\n",
    "    current_sfreq = raw.info[\"sfreq\"]\n",
    "    desired_sfreq = 128  # Hz\n",
    "    decim = np.round(current_sfreq / desired_sfreq).astype(int)\n",
    "    if ica:\n",
    "        iir_params = dict(order=2, ftype='butter',verbose=False)\n",
    "        raw = raw.copy()\n",
    "        raw = raw.filter(l_freq=1, h_freq=None, method='iir', iir_params=iir_params, phase='zero', verbose=False)\n",
    "    event_labels = [int(marker[0]) for marker in marker_stream['time_series']]\n",
    "    events = np.array([[sample, 0, label] for sample, label in zip(event_samples, event_labels)])\n",
    "    selected_events = events[events[:, 2] == marker_id]\n",
    "    epochs = mne.Epochs(raw, np.array(selected_events), event_id=int(marker_id),baseline=None, tmin=tmin, tmax=tmax, reject_by_annotation=False, verbose=False, preload=preload, decim=decim)\n",
    "    return epochs\n",
    "\n",
    "# Counts the markers and saves them in a file.\n",
    "def count_markers(marker_stream, match = False):\n",
    "    flat_list = [int(marker[0]) for marker in marker_stream['time_series']]\n",
    "    marker_count = {}\n",
    "    for marker in flat_list:\n",
    "        if marker in marker_count:\n",
    "            marker_count[marker] += 1\n",
    "        else:\n",
    "            marker_count[marker] = 1\n",
    "    marker_count = dict(sorted(marker_count.items()))\n",
    "    if match:\n",
    "        with open(f'markers\\\\{match}_markers.txt', 'w') as file:\n",
    "            for key, value in marker_count.items():\n",
    "                file.write(f\"{key}: {value}\\n\")\n",
    "    #return marker_count\n",
    "\n",
    "# ICA applied to individual epochs. Outdated function\n",
    "def apply_ica_indiv(epochs: mne.Epochs):\n",
    "    cleaned_epochs = []\n",
    "    all_rej = []\n",
    "    i = 0\n",
    "    while i < np.shape(epochs.events)[0]:\n",
    "        epoch = epochs[i]\n",
    "        ica = mne.preprocessing.ICA(n_components=32, method='fastica', random_state=42)\n",
    "        ica.fit(epoch)\n",
    "        source = ica.get_sources(epoch).get_data()\n",
    "        std = np.std(source)\n",
    "        rej_ch = []\n",
    "        for j, channel in enumerate(source[0]):\n",
    "            if np.max(channel) > 5*std:     # This has been chosen somewhat arbitrarily now as it results in\n",
    "                rej_ch.append(j)\n",
    "        all_rej.append(rej_ch)\n",
    "\n",
    "        cleaned_epochs.append(ica.apply(epoch, exclude=rej_ch))\n",
    "        i+=1\n",
    "    cleaned_epochs = mne.EpochsArray(\n",
    "        data = np.squeeze([e.get_data() for e in cleaned_epochs]),\n",
    "        info = epochs.info,\n",
    "        events= epochs.events\n",
    "    )\n",
    "    return cleaned_epochs\n",
    "\n",
    "# Naive way of ICA component rejection, based on maximum amplitude of component.\n",
    "def get_ica(epochs: mne.Epochs, n_components=32, plot=False, save_path=None, match=None):\n",
    "    ica = mne.preprocessing.ICA(n_components=n_components, max_iter= 1500, method='fastica', verbose=False)\n",
    "    ica.fit(epochs, verbose=False)\n",
    "    #std = np.std(ica.get_sources(epochs).get_data())\n",
    "    rej_ch = []\n",
    "    for i, channel in enumerate(ica.get_sources(epochs).get_data()[0]):\n",
    "        std = np.std(channel)\n",
    "        if np.max(np.absolute(channel)) > 6*std:\n",
    "            rej_ch.append(i)\n",
    "    if plot and len(rej_ch) != 0:\n",
    "        #print(len(rej_ch))\n",
    "        with open(f'figures\\\\meeting\\\\ica\\\\{match}.txt', 'w') as file:\n",
    "            file.write(\", \".join(map(str, rej_ch)))\n",
    "            file.write(f\"\\n{len(rej_ch)} rejected channels\")\n",
    "            file.close()\n",
    "        fig = ica.plot_components(title=f'{match} all ICA components', show=False);\n",
    "        for j, f in enumerate(fig):\n",
    "            f.savefig(save_path+f'{match}_{j}_all_ica.png')\n",
    "            plt.close(f)\n",
    "        fig = ica.plot_components(picks=rej_ch,title=f'{match} rejected channels', show=False);\n",
    "        fig.savefig(save_path+f'{match}_rejected_ica.png')\n",
    "        plt.close(fig)\n",
    "    return ica, rej_ch\n",
    "    #ica.apply(epochs, exclude=rej_ch, verbose=False)\n",
    "\n",
    "# ICA method using the mne implementation of icalabel\n",
    "def get_icalabel(epochs: mne.Epochs, n_components=32, plot=False, save_path=None, match=None):\n",
    "    \"\"\"\"\n",
    "    A function extracting the ICA components and rejecting all components that are not labeled Brain by the icalabel function. Using a certainty threshhold of 70%\n",
    "\n",
    "    epochs | mne epoch for which to calculate the ICA \\n\n",
    "    n_components | number of ICA components \\n\n",
    "    plot | whether to plot the ICA components \\n\n",
    "    save_path | path to save the ICA components \\n\n",
    "    match | the match regex that indicates the participant, trial and condition\n",
    "    \"\"\"\n",
    "    ica = mne.preprocessing.ICA(n_components=n_components, max_iter= 500, method='infomax', fit_params=dict(extended=True), verbose=False)\n",
    "    ica.fit(epochs, verbose=False)\n",
    "    rej_ch = []\n",
    "    a = label_components(epochs, ica, method='iclabel')\n",
    "    for i, ic in enumerate(a['labels']):\n",
    "        #print(f'Component {i} is {ic} with proba {a['y_pred_proba'][i]}')\n",
    "        if ic != 'brain':       #and a['y_pred_proba'][i] > 0.7\n",
    "            rej_ch.append(i)\n",
    "\n",
    "    # Ploitting the Components as well as Sources\n",
    "    print('Rejected components:', len(rej_ch))\n",
    "    if plot and len(rej_ch) != 0:\n",
    "        # Saving Rejected channelsin txt\n",
    "        with open(f'figures\\\\meeting\\\\ica\\\\{match}.txt', 'w') as file:\n",
    "            file.write(\", \".join(map(str, rej_ch)))\n",
    "            file.write(f\"\\n{len(rej_ch)} rejected channels\")\n",
    "            file.close()\n",
    "\n",
    "        # Plotting Components\n",
    "        fig = ica.plot_components(title=f'{match} all ICA components', show=False);\n",
    "        for j, f in enumerate(fig):\n",
    "            f.savefig(save_path+f'{match}_{j}_all_ica.png')\n",
    "            plt.close(f)\n",
    "        fig = ica.plot_components(picks=rej_ch,title=f'{match} rejected channels', show=False);\n",
    "        fig.savefig(save_path+f'{match}_rejected_ica.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Plotting Sources\n",
    "        fig = ica.plot_sources(epochs, picks=slice(0,32,1))\n",
    "        fig.savefig(save_path+f'{match}_ica_sources.png')\n",
    "        plt.close(fig)\n",
    "    return ica, rej_ch\n",
    "\n",
    "# load data, filter, epoch, ICA, average, plot\n",
    "def mrcp(epochs):\n",
    "    frontal_channels = ['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2']\n",
    "    iir_params = dict(order=2, ftype='butter')\n",
    "    epochs = epochs.filter(l_freq =0.1 ,h_freq=1, method='iir', iir_params=iir_params, phase='zero')\n",
    "    evoked = epochs.average()\n",
    "    evoked = evoked.pick(frontal_channels)\n",
    "    return evoked\n",
    "\n",
    "\n",
    "def drop_bad_epochs(epochs):\n",
    "    epoch_data = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n",
    "    std_per_channel = np.std(epoch_data, axis=(0, 2))  # Standard deviation per channel\n",
    "    threshold = 10 * std_per_channel[:, np.newaxis]  # Expand dims to match shape\n",
    "    # Find epochs where any channel exceeds the threshold\n",
    "    bad_epochs = np.any(np.abs(epoch_data) > threshold[np.newaxis, :, :], axis=(1, 2))\n",
    "    print(f'Bad epochs: {len(bad_epochs)}')\n",
    "    # Drop bad epochs\n",
    "    epochs_clean = epochs[~bad_epochs]\n",
    "    return epochs_clean\n",
    "\n",
    "# Given an epochs object, extracts the data for each 1s long window with a stepsize of 125ms. Creating 57 windwos (-4, 4) with each 110 features for all the epochs\n",
    "def extract_x_y(epochs):\n",
    "    epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "    start_times = np.arange(-4.0, 3.001, 0.125)\n",
    "    epochs.drop_bad(reject = dict(eeg=15e-5))\n",
    "    for i, epoch in enumerate(epochs):\n",
    "        raw = mne.io.RawArray(epoch, test.info)\n",
    "        sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "        X_features = sliding_window.reshape(sliding_window.shape[0], -1)\n",
    "        y = np.array([0 if t < -1.5 else 1 for t in start_times])\n",
    "\n",
    "        if i == 0:\n",
    "            x_combined = X_features\n",
    "            y_combined = y\n",
    "        else:\n",
    "            x_combined = np.concatenate([x_combined, X_features], axis=0)\n",
    "            y_combined = np.concatenate([y_combined, y], axis=0)\n",
    "    return x_combined, y_combined\n",
    "\n",
    "#adjust for 1009 and 1029\n",
    "def trial_correct_1009(y_true, y_pred, times):\n",
    "    correct_in_window = any(\n",
    "        (t >= -1.875 and t <= 0 and yt == 1 and yp == 1)\n",
    "        for t, yt, yp in zip(times, y_true, y_pred)\n",
    "    )\n",
    "    incorrect_before = any(\n",
    "        (t < -1.875 and yt == 0 and yp == 1)\n",
    "        for t, yt, yp in zip(times, y_true, y_pred)\n",
    "    )\n",
    "    return correct_in_window and not incorrect_before\n",
    "\n",
    "def trial_correct_1029(y_true, y_pred, times):\n",
    "    correct_in_window = any(\n",
    "        (t >= -0.875 and t <= 1 and yt == 1 and yp == 1)\n",
    "        for t, yt, yp in zip(times, y_true, y_pred)\n",
    "    )\n",
    "    incorrect_before = any(\n",
    "        (t < -0.875 and yt == 0 and yp == 1)\n",
    "        for t, yt, yp in zip(times, y_true, y_pred)\n",
    "    )\n",
    "    return correct_in_window and not incorrect_before"
   ],
   "id": "ccf3af989b620f6f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T10:19:41.385714Z",
     "start_time": "2025-07-16T10:19:41.384117Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "998770e53d4f6ff3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## In Condition Training and Testing\n",
    "\n",
    "Marker has to be selected manually, 1009 for the hand movement and 1029 for the start of VR movement marker\n"
   ],
   "id": "596aa5e69759c9ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T10:21:46.221660Z",
     "start_time": "2025-07-16T10:19:44.143058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Spliting train and test correctly\n",
    "score_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "score_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "conditions = ['Joystick', 'Leaning', 'Omnideck', 'Walking']\n",
    "marker = 1029\n",
    "for cond in conditions:\n",
    "    for p in range(1, 15):\n",
    "        if p in [4] or (p == 7 and cond == 'Leaning') or (p == 7 and cond == 'Joystick'):\n",
    "            score_dict_lda[cond].append(np.nan)\n",
    "            score_dict_svm[cond].append(np.nan)\n",
    "            accuracy_dict_lda[cond].append(np.nan)\n",
    "            accuracy_dict_svm[cond].append(np.nan)\n",
    "            continue\n",
    "\n",
    "        path = f'epochs\\\\P{p:03d}\\\\'\n",
    "        i = 1\n",
    "        x_combined = []\n",
    "        y_combined = []\n",
    "        trial_data = []\n",
    "\n",
    "        while i < 3:\n",
    "            # P13 only has one walking condition\n",
    "            if (p == 13 and cond == 'Walking' and i == 2) or (p == 3 and cond == 'Omnideck' and i == 2):\n",
    "                i+=1\n",
    "                continue\n",
    "            if marker == 1009:\n",
    "                filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_first_{marker}_epo.fif'     # Change to 1029\n",
    "            else:\n",
    "                filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_{marker}_epo.fif'\n",
    "            epochs = mne.read_epochs(path + filename)\n",
    "            epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "\n",
    "            # For 1029: -5, 0.0001; For 1009: -6, -0.999\n",
    "            if marker == 1009:\n",
    "                start_times = np.arange(-6, -0.999, 0.125)\n",
    "                epochs.crop(tmin=-6, tmax=0)\n",
    "            else:\n",
    "                start_times = np.arange(-5, 0.001, 0.125)\n",
    "                epochs.crop(tmin=-5, tmax=1)\n",
    "            epochs.resample(sfreq=10)\n",
    "\n",
    "            ### Loop over all Epochs and create Sliding windows ###\n",
    "            for j in range(len(epochs)):\n",
    "                epoch = mrcp(epochs[j])\n",
    "                # make_fixed_length_epochs can only be applied to raw data so I transform single epochs into raw by using the data and info from it\n",
    "                raw = mne.io.RawArray(epoch.get_data(), epochs.info)\n",
    "                sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "\n",
    "                # Normalizing the features to euclidean length\n",
    "                X = sliding_window.get_data()\n",
    "                X_features = X.reshape(X.shape[0], -1)\n",
    "                norms = np.linalg.norm(X_features, axis=1, keepdims=True)\n",
    "                norms[norms == 0] = 1.0\n",
    "                X_features = X_features / norms\n",
    "\n",
    "                # Constructing the correct labels for y; a sliding window is regarded as pre-movement if more than half of the window is in pre-movement state\n",
    "                y = []\n",
    "                for t in start_times:\n",
    "                    # For 1029: -0.875; For 1009: -1.87\n",
    "                    if marker == 1009:\n",
    "                        if t < -1.875:\n",
    "                            y.append(0)\n",
    "                        elif t > 0:\n",
    "                            y.append(0)\n",
    "                        else:\n",
    "                            y.append(1)\n",
    "                    else:\n",
    "                        if t < -0.875:\n",
    "                            y.append(0)\n",
    "                        elif t > 1:\n",
    "                            y.append(0)\n",
    "                        else:\n",
    "                            y.append(1)\n",
    "                y = np.array(y)\n",
    "\n",
    "                # Aggregating the epoch data\n",
    "                x_combined.append(X_features)\n",
    "                y_combined.append(y)\n",
    "                trial_data.append((X_features, y, start_times))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        # combining the two sessions of a condition\n",
    "        x_combined = np.concatenate(x_combined, axis=0)\n",
    "        y_combined = np.concatenate(y_combined, axis=0)\n",
    "\n",
    "        #initializing the classifiers, CV and scorer\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "        svm = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        f05_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "        # Perform window based classification\n",
    "        scores_lda = cross_val_score(lda, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "        scores_svm = cross_val_score(svm, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "\n",
    "        score_dict_lda[cond].append(scores_lda.mean())\n",
    "        score_dict_svm[cond].append(scores_svm.mean())\n",
    "\n",
    "        ### Start of Accuracy Evaluation ###\n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "        accuracies_lda = []\n",
    "        accuracies_svm = []\n",
    "        for train_idx, test_idx in kf.split(trial_data):\n",
    "            # Prepare data\n",
    "            train_trials = [trial_data[i] for i in train_idx]\n",
    "            test_trials = [trial_data[i] for i in test_idx]\n",
    "\n",
    "            X_train = np.concatenate([X for X, y, t in train_trials], axis=0)\n",
    "            y_train = np.concatenate([y for X, y, t in train_trials], axis=0)\n",
    "\n",
    "            # Fit classifiers\n",
    "            lda.fit(X_train, y_train)\n",
    "            svm.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate on test trials\n",
    "            correct_lda = 0\n",
    "            correct_svm = 0\n",
    "\n",
    "            for X_trial, y_trial, t_trial in test_trials:\n",
    "                y_pred_lda = lda.predict(X_trial)\n",
    "                y_pred_svm = svm.predict(X_trial)\n",
    "                if marker == 1009:\n",
    "                    if trial_correct_1009(y_trial, y_pred_lda, t_trial):\n",
    "                        correct_lda += 1\n",
    "                    if trial_correct_1009(y_trial, y_pred_svm, t_trial):\n",
    "                        correct_svm += 1\n",
    "                else:\n",
    "                    if trial_correct_1029(y_trial, y_pred_lda, t_trial):\n",
    "                        correct_lda += 1\n",
    "                    if trial_correct_1029(y_trial, y_pred_svm, t_trial):\n",
    "                        correct_svm += 1\n",
    "\n",
    "            fold_accuracy_lda = correct_lda / len(test_trials)\n",
    "            fold_accuracy_svm = correct_svm / len(test_trials)\n",
    "\n",
    "            accuracies_lda.append(fold_accuracy_lda)\n",
    "            accuracies_svm.append(fold_accuracy_svm)\n",
    "\n",
    "        # Store average accuracy over 5 folds\n",
    "        accuracy_dict_lda[cond].append(np.mean(accuracies_lda))\n",
    "        accuracy_dict_svm[cond].append(np.mean(accuracies_svm))\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean LDA F0.5 Score: {scores_lda.mean():.3f} | Accuracy: {np.mean(accuracies_lda):.3f}\")\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean SVM F0.5 Score: {scores_svm.mean():.3f} | Accuracy: {np.mean(accuracies_svm):.3f}\")\n",
    "        print(f\"Participant {p} | LDA CV {accuracies_lda} | SVM CV {accuracies_svm}\")\n",
    "\n",
    "# Print group means\n",
    "for cond in conditions:\n",
    "    print(f\"{cond} | LDA Mean F0.5 Score: {np.nanmean(score_dict_lda[cond]):.3f} | LDA Accuracy: {np.nanmean(accuracy_dict_lda[cond]):.3f}\")\n",
    "    print(f\"{cond} | SVM Mean F0.5 Score: {np.nanmean(score_dict_svm[cond]):.3f} | SVM Accuracy: {np.nanmean(accuracy_dict_svm[cond]):.3f}\")\n",
    "\n",
    "# Convert results to DataFrame for saving\n",
    "participants = list(range(0, 14))\n",
    "# Exclude participants that were skipped per condition\n",
    "def get_valid_scores(score_dict, cond):\n",
    "    valid_scores = []\n",
    "    for idx, p in enumerate(participants):\n",
    "        if (p in [4]) or (p == 3 and cond == 'Omnideck') or (p == 7 and cond == 'Leaning') or (p == 7 and cond == 'Joystick'):\n",
    "            valid_scores.append(np.nan)\n",
    "        else:\n",
    "            valid_scores.append(score_dict[cond][len(valid_scores)])\n",
    "    return valid_scores\n",
    "# Create list of records (rows)\n",
    "rows = []\n",
    "for cond in conditions:\n",
    "    for i, p in enumerate(participants):\n",
    "        row = {\n",
    "            \"Participant\": p+1,\n",
    "            \"Condition\": cond,\n",
    "            \"LDA_F0.5_Score\": score_dict_lda[cond][i],\n",
    "            \"SVM_F0.5_Score\": score_dict_svm[cond][i],\n",
    "            \"LDA_Accuracy\": accuracy_dict_lda[cond][i],\n",
    "            \"SVM_Accuracy\": accuracy_dict_svm[cond][i]\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Save to CSV\n",
    "if marker == 1009:\n",
    "    df.to_csv(f\"results\\\\classification_results_single_cond_first_{marker}.csv\", index=False)\n",
    "else:\n",
    "    df.to_csv(f\"results\\\\classification_results_single_cond_{marker}.csv\", index=False)\n",
    "print(\"Results saved to classification_results.csv\")\n"
   ],
   "id": "c6fbf31187d02537",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant 1 | Condition Joystick | Mean LDA F0.5 Score: 0.539 | Accuracy: 0.257\n",
      "Participant 1 | Condition Joystick | Mean SVM F0.5 Score: 0.728 | Accuracy: 0.182\n",
      "Participant 1 | LDA CV [0.375, 0.375, 0.25, 0.14285714285714285, 0.14285714285714285] | SVM CV [0.25, 0.375, 0.0, 0.2857142857142857, 0.0]\n",
      "Participant 2 | Condition Joystick | Mean LDA F0.5 Score: 0.607 | Accuracy: 0.261\n",
      "Participant 2 | Condition Joystick | Mean SVM F0.5 Score: 0.828 | Accuracy: 0.289\n",
      "Participant 2 | LDA CV [0.375, 0.375, 0.125, 0.2857142857142857, 0.14285714285714285] | SVM CV [0.0, 0.5, 0.375, 0.2857142857142857, 0.2857142857142857]\n",
      "Participant 3 | Condition Joystick | Mean LDA F0.5 Score: 0.555 | Accuracy: 0.368\n",
      "Participant 3 | Condition Joystick | Mean SVM F0.5 Score: 0.762 | Accuracy: 0.243\n",
      "Participant 3 | LDA CV [0.5, 0.125, 0.5, 0.5714285714285714, 0.14285714285714285] | SVM CV [0.125, 0.25, 0.125, 0.42857142857142855, 0.2857142857142857]\n",
      "Participant 5 | Condition Joystick | Mean LDA F0.5 Score: 0.589 | Accuracy: 0.293\n",
      "Participant 5 | Condition Joystick | Mean SVM F0.5 Score: 0.696 | Accuracy: 0.321\n",
      "Participant 5 | LDA CV [0.125, 0.125, 0.5, 0.2857142857142857, 0.42857142857142855] | SVM CV [0.125, 0.125, 0.5, 0.2857142857142857, 0.5714285714285714]\n",
      "Participant 6 | Condition Joystick | Mean LDA F0.5 Score: 0.726 | Accuracy: 0.364\n",
      "Participant 6 | Condition Joystick | Mean SVM F0.5 Score: 0.825 | Accuracy: 0.471\n",
      "Participant 6 | LDA CV [0.625, 0.25, 0.375, 0.2857142857142857, 0.2857142857142857] | SVM CV [0.5, 0.5, 0.5, 0.2857142857142857, 0.5714285714285714]\n",
      "Participant 8 | Condition Joystick | Mean LDA F0.5 Score: 0.634 | Accuracy: 0.236\n",
      "Participant 8 | Condition Joystick | Mean SVM F0.5 Score: 0.798 | Accuracy: 0.314\n",
      "Participant 8 | LDA CV [0.375, 0.25, 0.125, 0.42857142857142855, 0.0] | SVM CV [0.375, 0.25, 0.375, 0.42857142857142855, 0.14285714285714285]\n",
      "Participant 9 | Condition Joystick | Mean LDA F0.5 Score: 0.556 | Accuracy: 0.350\n",
      "Participant 9 | Condition Joystick | Mean SVM F0.5 Score: 0.726 | Accuracy: 0.236\n",
      "Participant 9 | LDA CV [0.0, 0.375, 0.375, 0.42857142857142855, 0.5714285714285714] | SVM CV [0.125, 0.375, 0.25, 0.14285714285714285, 0.2857142857142857]\n",
      "Participant 10 | Condition Joystick | Mean LDA F0.5 Score: 0.690 | Accuracy: 0.371\n",
      "Participant 10 | Condition Joystick | Mean SVM F0.5 Score: 0.835 | Accuracy: 0.500\n",
      "Participant 10 | LDA CV [0.375, 0.125, 0.5, 0.14285714285714285, 0.7142857142857143] | SVM CV [0.5, 0.375, 0.625, 0.42857142857142855, 0.5714285714285714]\n",
      "Participant 11 | Condition Joystick | Mean LDA F0.5 Score: 0.682 | Accuracy: 0.293\n",
      "Participant 11 | Condition Joystick | Mean SVM F0.5 Score: 0.760 | Accuracy: 0.339\n",
      "Participant 11 | LDA CV [0.0, 0.25, 0.5, 0.2857142857142857, 0.42857142857142855] | SVM CV [0.125, 0.25, 0.75, 0.2857142857142857, 0.2857142857142857]\n",
      "Participant 12 | Condition Joystick | Mean LDA F0.5 Score: 0.601 | Accuracy: 0.161\n",
      "Participant 12 | Condition Joystick | Mean SVM F0.5 Score: 0.841 | Accuracy: 0.371\n",
      "Participant 12 | LDA CV [0.125, 0.25, 0.0, 0.14285714285714285, 0.2857142857142857] | SVM CV [0.375, 0.25, 0.375, 0.14285714285714285, 0.7142857142857143]\n",
      "Participant 13 | Condition Joystick | Mean LDA F0.5 Score: 0.530 | Accuracy: 0.229\n",
      "Participant 13 | Condition Joystick | Mean SVM F0.5 Score: 0.622 | Accuracy: 0.150\n",
      "Participant 13 | LDA CV [0.25, 0.625, 0.125, 0.14285714285714285, 0.0] | SVM CV [0.25, 0.25, 0.25, 0.0, 0.0]\n",
      "Participant 14 | Condition Joystick | Mean LDA F0.5 Score: 0.695 | Accuracy: 0.371\n",
      "Participant 14 | Condition Joystick | Mean SVM F0.5 Score: 0.855 | Accuracy: 0.364\n",
      "Participant 14 | LDA CV [0.5, 0.375, 0.125, 0.42857142857142855, 0.42857142857142855] | SVM CV [0.375, 0.5, 0.375, 0.14285714285714285, 0.42857142857142855]\n",
      "Participant 1 | Condition Leaning | Mean LDA F0.5 Score: 0.556 | Accuracy: 0.182\n",
      "Participant 1 | Condition Leaning | Mean SVM F0.5 Score: 0.786 | Accuracy: 0.318\n",
      "Participant 1 | LDA CV [0.125, 0.25, 0.25, 0.2857142857142857, 0.0] | SVM CV [0.375, 0.5, 0.0, 0.42857142857142855, 0.2857142857142857]\n",
      "Participant 2 | Condition Leaning | Mean LDA F0.5 Score: 0.557 | Accuracy: 0.314\n",
      "Participant 2 | Condition Leaning | Mean SVM F0.5 Score: 0.745 | Accuracy: 0.264\n",
      "Participant 2 | LDA CV [0.5, 0.25, 0.25, 0.2857142857142857, 0.2857142857142857] | SVM CV [0.125, 0.375, 0.25, 0.2857142857142857, 0.2857142857142857]\n",
      "Participant 3 | Condition Leaning | Mean LDA F0.5 Score: 0.567 | Accuracy: 0.346\n",
      "Participant 3 | Condition Leaning | Mean SVM F0.5 Score: 0.758 | Accuracy: 0.289\n",
      "Participant 3 | LDA CV [0.5, 0.0, 0.375, 0.5714285714285714, 0.2857142857142857] | SVM CV [0.375, 0.25, 0.25, 0.2857142857142857, 0.2857142857142857]\n",
      "Participant 5 | Condition Leaning | Mean LDA F0.5 Score: 0.579 | Accuracy: 0.289\n",
      "Participant 5 | Condition Leaning | Mean SVM F0.5 Score: 0.684 | Accuracy: 0.293\n",
      "Participant 5 | LDA CV [0.375, 0.375, 0.125, 0.5714285714285714, 0.0] | SVM CV [0.5, 0.25, 0.0, 0.5714285714285714, 0.14285714285714285]\n",
      "Participant 6 | Condition Leaning | Mean LDA F0.5 Score: 0.476 | Accuracy: 0.107\n",
      "Participant 6 | Condition Leaning | Mean SVM F0.5 Score: 0.791 | Accuracy: 0.157\n",
      "Participant 6 | LDA CV [0.0, 0.125, 0.125, 0.14285714285714285, 0.14285714285714285] | SVM CV [0.25, 0.125, 0.125, 0.2857142857142857, 0.0]\n",
      "Participant 8 | Condition Leaning | Mean LDA F0.5 Score: 0.717 | Accuracy: 0.243\n",
      "Participant 8 | Condition Leaning | Mean SVM F0.5 Score: 0.845 | Accuracy: 0.368\n",
      "Participant 8 | LDA CV [0.125, 0.25, 0.125, 0.42857142857142855, 0.2857142857142857] | SVM CV [0.375, 0.375, 0.375, 0.2857142857142857, 0.42857142857142855]\n",
      "Participant 9 | Condition Leaning | Mean LDA F0.5 Score: 0.656 | Accuracy: 0.336\n",
      "Participant 9 | Condition Leaning | Mean SVM F0.5 Score: 0.777 | Accuracy: 0.246\n",
      "Participant 9 | LDA CV [0.5, 0.25, 0.5, 0.2857142857142857, 0.14285714285714285] | SVM CV [0.125, 0.0, 0.25, 0.2857142857142857, 0.5714285714285714]\n",
      "Participant 10 | Condition Leaning | Mean LDA F0.5 Score: 0.712 | Accuracy: 0.375\n",
      "Participant 10 | Condition Leaning | Mean SVM F0.5 Score: 0.822 | Accuracy: 0.404\n",
      "Participant 10 | LDA CV [0.25, 0.25, 0.375, 0.42857142857142855, 0.5714285714285714] | SVM CV [0.375, 0.375, 0.125, 0.5714285714285714, 0.5714285714285714]\n",
      "Participant 11 | Condition Leaning | Mean LDA F0.5 Score: 0.659 | Accuracy: 0.350\n",
      "Participant 11 | Condition Leaning | Mean SVM F0.5 Score: 0.869 | Accuracy: 0.350\n",
      "Participant 11 | LDA CV [0.5, 0.25, 0.0, 0.2857142857142857, 0.7142857142857143] | SVM CV [0.25, 0.25, 0.25, 0.5714285714285714, 0.42857142857142855]\n",
      "Participant 12 | Condition Leaning | Mean LDA F0.5 Score: 0.499 | Accuracy: 0.111\n",
      "Participant 12 | Condition Leaning | Mean SVM F0.5 Score: 0.821 | Accuracy: 0.396\n",
      "Participant 12 | LDA CV [0.0, 0.125, 0.0, 0.2857142857142857, 0.14285714285714285] | SVM CV [0.375, 0.625, 0.125, 0.5714285714285714, 0.2857142857142857]\n",
      "Participant 13 | Condition Leaning | Mean LDA F0.5 Score: 0.629 | Accuracy: 0.229\n",
      "Participant 13 | Condition Leaning | Mean SVM F0.5 Score: 0.792 | Accuracy: 0.229\n",
      "Participant 13 | LDA CV [0.375, 0.375, 0.25, 0.0, 0.14285714285714285] | SVM CV [0.375, 0.25, 0.375, 0.0, 0.14285714285714285]\n",
      "Participant 14 | Condition Leaning | Mean LDA F0.5 Score: 0.407 | Accuracy: 0.154\n",
      "Participant 14 | Condition Leaning | Mean SVM F0.5 Score: 0.683 | Accuracy: 0.207\n",
      "Participant 14 | LDA CV [0.25, 0.25, 0.125, 0.14285714285714285, 0.0] | SVM CV [0.25, 0.375, 0.125, 0.14285714285714285, 0.14285714285714285]\n",
      "Participant 1 | Condition Omnideck | Mean LDA F0.5 Score: 0.600 | Accuracy: 0.296\n",
      "Participant 1 | Condition Omnideck | Mean SVM F0.5 Score: 0.759 | Accuracy: 0.318\n",
      "Participant 1 | LDA CV [0.375, 0.25, 0.0, 0.42857142857142855, 0.42857142857142855] | SVM CV [0.5, 0.375, 0.2857142857142857, 0.2857142857142857, 0.14285714285714285]\n",
      "Participant 2 | Condition Omnideck | Mean LDA F0.5 Score: 0.434 | Accuracy: 0.182\n",
      "Participant 2 | Condition Omnideck | Mean SVM F0.5 Score: 0.749 | Accuracy: 0.157\n",
      "Participant 2 | LDA CV [0.125, 0.125, 0.375, 0.0, 0.2857142857142857] | SVM CV [0.25, 0.0, 0.25, 0.0, 0.2857142857142857]\n",
      "Participant 3 | Condition Omnideck | Mean LDA F0.5 Score: 0.571 | Accuracy: 0.300\n",
      "Participant 3 | Condition Omnideck | Mean SVM F0.5 Score: 0.825 | Accuracy: 0.383\n",
      "Participant 3 | LDA CV [0.0, 0.75, 0.25, 0.5, 0.0] | SVM CV [0.25, 0.25, 0.25, 0.5, 0.6666666666666666]\n",
      "Participant 5 | Condition Omnideck | Mean LDA F0.5 Score: 0.531 | Accuracy: 0.293\n",
      "Participant 5 | Condition Omnideck | Mean SVM F0.5 Score: 0.758 | Accuracy: 0.239\n",
      "Participant 5 | LDA CV [0.25, 0.25, 0.25, 0.42857142857142855, 0.2857142857142857] | SVM CV [0.125, 0.25, 0.25, 0.5714285714285714, 0.0]\n",
      "Participant 6 | Condition Omnideck | Mean LDA F0.5 Score: 0.684 | Accuracy: 0.289\n",
      "Participant 6 | Condition Omnideck | Mean SVM F0.5 Score: 0.859 | Accuracy: 0.393\n",
      "Participant 6 | LDA CV [0.125, 0.375, 0.375, 0.5714285714285714, 0.0] | SVM CV [0.5, 0.375, 0.375, 0.5714285714285714, 0.14285714285714285]\n",
      "Participant 7 | Condition Omnideck | Mean LDA F0.5 Score: 0.639 | Accuracy: 0.343\n",
      "Participant 7 | Condition Omnideck | Mean SVM F0.5 Score: 0.787 | Accuracy: 0.346\n",
      "Participant 7 | LDA CV [0.125, 0.375, 0.5, 0.2857142857142857, 0.42857142857142855] | SVM CV [0.125, 0.375, 0.375, 0.2857142857142857, 0.5714285714285714]\n",
      "Participant 8 | Condition Omnideck | Mean LDA F0.5 Score: 0.679 | Accuracy: 0.321\n",
      "Participant 8 | Condition Omnideck | Mean SVM F0.5 Score: 0.849 | Accuracy: 0.425\n",
      "Participant 8 | LDA CV [0.125, 0.0, 0.625, 0.2857142857142857, 0.5714285714285714] | SVM CV [0.5, 0.25, 0.375, 0.5714285714285714, 0.42857142857142855]\n",
      "Participant 9 | Condition Omnideck | Mean LDA F0.5 Score: 0.386 | Accuracy: 0.207\n",
      "Participant 9 | Condition Omnideck | Mean SVM F0.5 Score: 0.692 | Accuracy: 0.261\n",
      "Participant 9 | LDA CV [0.125, 0.25, 0.375, 0.2857142857142857, 0.0] | SVM CV [0.375, 0.375, 0.125, 0.2857142857142857, 0.14285714285714285]\n",
      "Participant 10 | Condition Omnideck | Mean LDA F0.5 Score: 0.574 | Accuracy: 0.393\n",
      "Participant 10 | Condition Omnideck | Mean SVM F0.5 Score: 0.817 | Accuracy: 0.268\n",
      "Participant 10 | LDA CV [0.75, 0.375, 0.125, 0.42857142857142855, 0.2857142857142857] | SVM CV [0.375, 0.125, 0.125, 0.5714285714285714, 0.14285714285714285]\n",
      "Participant 11 | Condition Omnideck | Mean LDA F0.5 Score: 0.641 | Accuracy: 0.454\n",
      "Participant 11 | Condition Omnideck | Mean SVM F0.5 Score: 0.811 | Accuracy: 0.325\n",
      "Participant 11 | LDA CV [0.25, 0.5, 0.375, 0.7142857142857143, 0.42857142857142855] | SVM CV [0.125, 0.375, 0.125, 0.2857142857142857, 0.7142857142857143]\n",
      "Participant 12 | Condition Omnideck | Mean LDA F0.5 Score: 0.499 | Accuracy: 0.214\n",
      "Participant 12 | Condition Omnideck | Mean SVM F0.5 Score: 0.807 | Accuracy: 0.314\n",
      "Participant 12 | LDA CV [0.25, 0.125, 0.125, 0.2857142857142857, 0.2857142857142857] | SVM CV [0.125, 0.5, 0.375, 0.2857142857142857, 0.2857142857142857]\n",
      "Participant 13 | Condition Omnideck | Mean LDA F0.5 Score: 0.435 | Accuracy: 0.236\n",
      "Participant 13 | Condition Omnideck | Mean SVM F0.5 Score: 0.696 | Accuracy: 0.318\n",
      "Participant 13 | LDA CV [0.25, 0.125, 0.375, 0.2857142857142857, 0.14285714285714285] | SVM CV [0.25, 0.125, 0.5, 0.2857142857142857, 0.42857142857142855]\n",
      "Participant 14 | Condition Omnideck | Mean LDA F0.5 Score: 0.773 | Accuracy: 0.393\n",
      "Participant 14 | Condition Omnideck | Mean SVM F0.5 Score: 0.839 | Accuracy: 0.475\n",
      "Participant 14 | LDA CV [0.5, 0.25, 0.5, 0.14285714285714285, 0.5714285714285714] | SVM CV [0.625, 0.25, 0.5, 0.42857142857142855, 0.5714285714285714]\n",
      "Participant 1 | Condition Walking | Mean LDA F0.5 Score: 0.739 | Accuracy: 0.261\n",
      "Participant 1 | Condition Walking | Mean SVM F0.5 Score: 0.809 | Accuracy: 0.318\n",
      "Participant 1 | LDA CV [0.25, 0.375, 0.25, 0.2857142857142857, 0.14285714285714285] | SVM CV [0.125, 0.25, 0.5, 0.5714285714285714, 0.14285714285714285]\n",
      "Participant 2 | Condition Walking | Mean LDA F0.5 Score: 0.611 | Accuracy: 0.343\n",
      "Participant 2 | Condition Walking | Mean SVM F0.5 Score: 0.744 | Accuracy: 0.189\n",
      "Participant 2 | LDA CV [0.375, 0.375, 0.25, 0.42857142857142855, 0.2857142857142857] | SVM CV [0.125, 0.125, 0.125, 0.2857142857142857, 0.2857142857142857]\n",
      "Participant 3 | Condition Walking | Mean LDA F0.5 Score: 0.713 | Accuracy: 0.318\n",
      "Participant 3 | Condition Walking | Mean SVM F0.5 Score: 0.821 | Accuracy: 0.339\n",
      "Participant 3 | LDA CV [0.25, 0.25, 0.375, 0.42857142857142855, 0.2857142857142857] | SVM CV [0.375, 0.25, 0.5, 0.2857142857142857, 0.2857142857142857]\n",
      "Participant 5 | Condition Walking | Mean LDA F0.5 Score: 0.354 | Accuracy: 0.079\n",
      "Participant 5 | Condition Walking | Mean SVM F0.5 Score: 0.534 | Accuracy: 0.111\n",
      "Participant 5 | LDA CV [0.25, 0.0, 0.0, 0.14285714285714285, 0.0] | SVM CV [0.125, 0.0, 0.0, 0.14285714285714285, 0.2857142857142857]\n",
      "Participant 6 | Condition Walking | Mean LDA F0.5 Score: 0.729 | Accuracy: 0.264\n",
      "Participant 6 | Condition Walking | Mean SVM F0.5 Score: 0.767 | Accuracy: 0.318\n",
      "Participant 6 | LDA CV [0.25, 0.0, 0.5, 0.42857142857142855, 0.14285714285714285] | SVM CV [0.25, 0.375, 0.25, 0.5714285714285714, 0.14285714285714285]\n",
      "Participant 7 | Condition Walking | Mean LDA F0.5 Score: 0.611 | Accuracy: 0.211\n",
      "Participant 7 | Condition Walking | Mean SVM F0.5 Score: 0.744 | Accuracy: 0.296\n",
      "Participant 7 | LDA CV [0.25, 0.125, 0.25, 0.0, 0.42857142857142855] | SVM CV [0.25, 0.25, 0.125, 0.42857142857142855, 0.42857142857142855]\n",
      "Participant 8 | Condition Walking | Mean LDA F0.5 Score: 0.658 | Accuracy: 0.343\n",
      "Participant 8 | Condition Walking | Mean SVM F0.5 Score: 0.853 | Accuracy: 0.532\n",
      "Participant 8 | LDA CV [0.75, 0.125, 0.125, 0.42857142857142855, 0.2857142857142857] | SVM CV [0.625, 0.25, 0.5, 0.42857142857142855, 0.8571428571428571]\n",
      "Participant 9 | Condition Walking | Mean LDA F0.5 Score: 0.657 | Accuracy: 0.418\n",
      "Participant 9 | Condition Walking | Mean SVM F0.5 Score: 0.770 | Accuracy: 0.286\n",
      "Participant 9 | LDA CV [0.5, 0.125, 0.75, 0.2857142857142857, 0.42857142857142855] | SVM CV [0.25, 0.25, 0.5, 0.14285714285714285, 0.2857142857142857]\n",
      "Participant 10 | Condition Walking | Mean LDA F0.5 Score: 0.640 | Accuracy: 0.450\n",
      "Participant 10 | Condition Walking | Mean SVM F0.5 Score: 0.773 | Accuracy: 0.475\n",
      "Participant 10 | LDA CV [0.25, 0.625, 0.375, 0.2857142857142857, 0.7142857142857143] | SVM CV [0.375, 0.625, 0.375, 0.2857142857142857, 0.7142857142857143]\n",
      "Participant 11 | Condition Walking | Mean LDA F0.5 Score: 0.707 | Accuracy: 0.343\n",
      "Participant 11 | Condition Walking | Mean SVM F0.5 Score: 0.848 | Accuracy: 0.321\n",
      "Participant 11 | LDA CV [0.25, 0.25, 0.5, 0.2857142857142857, 0.42857142857142855] | SVM CV [0.125, 0.375, 0.25, 0.2857142857142857, 0.5714285714285714]\n",
      "Participant 12 | Condition Walking | Mean LDA F0.5 Score: 0.453 | Accuracy: 0.268\n",
      "Participant 12 | Condition Walking | Mean SVM F0.5 Score: 0.860 | Accuracy: 0.189\n",
      "Participant 12 | LDA CV [0.125, 0.125, 0.375, 0.2857142857142857, 0.42857142857142855] | SVM CV [0.125, 0.125, 0.125, 0.14285714285714285, 0.42857142857142855]\n",
      "Participant 13 | Condition Walking | Mean LDA F0.5 Score: 0.650 | Accuracy: 0.433\n",
      "Participant 13 | Condition Walking | Mean SVM F0.5 Score: 0.533 | Accuracy: 0.233\n",
      "Participant 13 | LDA CV [0.5, 0.75, 0.0, 0.25, 0.6666666666666666] | SVM CV [0.25, 0.0, 0.25, 0.0, 0.6666666666666666]\n",
      "Participant 14 | Condition Walking | Mean LDA F0.5 Score: 0.806 | Accuracy: 0.339\n",
      "Participant 14 | Condition Walking | Mean SVM F0.5 Score: 0.847 | Accuracy: 0.389\n",
      "Participant 14 | LDA CV [0.375, 0.375, 0.375, 0.42857142857142855, 0.14285714285714285] | SVM CV [0.25, 0.5, 0.625, 0.5714285714285714, 0.0]\n",
      "Joystick | LDA Mean F0.5 Score: 0.617 | LDA Accuracy: 0.296\n",
      "Joystick | SVM Mean F0.5 Score: 0.773 | SVM Accuracy: 0.315\n",
      "Leaning | LDA Mean F0.5 Score: 0.584 | LDA Accuracy: 0.253\n",
      "Leaning | SVM Mean F0.5 Score: 0.781 | SVM Accuracy: 0.293\n",
      "Omnideck | LDA Mean F0.5 Score: 0.573 | LDA Accuracy: 0.302\n",
      "Omnideck | SVM Mean F0.5 Score: 0.788 | SVM Accuracy: 0.325\n",
      "Walking | LDA Mean F0.5 Score: 0.641 | LDA Accuracy: 0.313\n",
      "Walking | SVM Mean F0.5 Score: 0.762 | SVM Accuracy: 0.308\n",
      "Results saved to classification_results.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:47:20.927447Z",
     "start_time": "2025-07-15T11:47:18.330039Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO: Chance level Estimate",
   "id": "c183546c600070e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Global Chance-Level Accuracy: 0.0000300000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3e-05"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Leave one Condition out Transferlearning",
   "id": "ec766717b1ff4bf7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T10:25:31.230033Z",
     "start_time": "2025-07-16T10:21:46.330649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "score_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "score_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "\n",
    "conditions = ['Joystick', 'Leaning', 'Omnideck', 'Walking']\n",
    "participants = list(range(1, 15))\n",
    "excluded = {\n",
    "    (3, 'Omnideck'), (4, 'Joystick'), (7, 'Leaning'), (7, 'Joystick'), (13, 'Walking')\n",
    "}\n",
    "marker = 1029\n",
    "for p in participants:\n",
    "    for test_cond in conditions:\n",
    "        ### Dealing with Missing data ###\n",
    "        if (p, test_cond) in excluded:\n",
    "            score_dict_lda[test_cond].append(np.nan)\n",
    "            score_dict_svm[test_cond].append(np.nan)\n",
    "            accuracy_dict_lda[test_cond].append(np.nan)\n",
    "            accuracy_dict_svm[test_cond].append(np.nan)\n",
    "            continue\n",
    "\n",
    "        path = f'epochs\\\\P{p:03d}\\\\'\n",
    "        x_train, y_train = [], []\n",
    "        x_test, y_test = [], []\n",
    "        test_trials = []\n",
    "\n",
    "        for cond in conditions:\n",
    "            if (p, cond) in excluded:\n",
    "                continue\n",
    "            for i in range(1, 3):\n",
    "                if p == 13 and cond == 'Walking' and i == 2:\n",
    "                    continue\n",
    "\n",
    "                if marker == 1009:\n",
    "                    filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_first_{marker}_epo.fif'\n",
    "                else:\n",
    "                    filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_{marker}_epo.fif'\n",
    "\n",
    "                # If files does not exist\n",
    "                try:\n",
    "                    epochs = mne.read_epochs(path + filename, verbose='error')\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"File {filename} not found\")\n",
    "                    continue\n",
    "\n",
    "                # Arranging the start times correctly based on marker; 1029 is delayed by one second\n",
    "                epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "                if marker == 1009:\n",
    "                    start_times = np.arange(-6, -0.999, 0.125)\n",
    "                    epochs.crop(tmin=-6, tmax=0)\n",
    "                else:\n",
    "                    start_times = np.arange(-5, 0.0001, 0.125)\n",
    "                    epochs.crop(tmin=-5, tmax=1)\n",
    "                epochs.resample(sfreq=10)\n",
    "\n",
    "                # Loop through all epochs create the sliding windows and labels\n",
    "                for j in range(len(epochs)):\n",
    "                    epoch = mrcp(epochs[j])\n",
    "                    raw = mne.io.RawArray(epoch.get_data(), epochs.info)\n",
    "                    sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "                    X = sliding_window.get_data()\n",
    "                    X_features = X.reshape(X.shape[0], -1)\n",
    "                    norms = np.linalg.norm(X_features, axis=1, keepdims=True)\n",
    "                    norms[norms == 0] = 1.0\n",
    "                    X_features = X_features / norms\n",
    "\n",
    "                    # cleaner code using list comprehensions\n",
    "                    if marker == 1009:\n",
    "                        y = [1 if -1.875 <= t <= 0 else 0 for t in start_times]\n",
    "                    else:\n",
    "                        y = [1 if -0.875 <= t <= 1 else 0 for t in start_times]\n",
    "                    y = np.array(y)\n",
    "\n",
    "                    # Aggregate the data based on the current test condition\n",
    "                    if cond == test_cond:\n",
    "                        x_test.append(X_features)\n",
    "                        y_test.append(y)\n",
    "                        test_trials.append((X_features, y, start_times))\n",
    "                    else:\n",
    "                        x_train.append(X_features)\n",
    "                        y_train.append(y)\n",
    "\n",
    "        # Deal with missing possible missing conditions if not flagged earlier\n",
    "        if not x_train or not x_test:\n",
    "            score_dict_lda[test_cond].append(np.nan)\n",
    "            score_dict_svm[test_cond].append(np.nan)\n",
    "            accuracy_dict_lda[test_cond].append(np.nan)\n",
    "            accuracy_dict_svm[test_cond].append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Create the test and train data\n",
    "        x_train = np.concatenate(x_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "        x_test_all = np.concatenate(x_test, axis=0)\n",
    "        y_test_all = np.concatenate(y_test, axis=0)\n",
    "\n",
    "        # Initialize Classifiers\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "        svm = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "        # Fit Classifiers\n",
    "        lda.fit(x_train, y_train)\n",
    "        svm.fit(x_train, y_train)\n",
    "\n",
    "        # Predict test set and score based on F0.5-score\n",
    "        y_pred_lda = lda.predict(x_test_all)\n",
    "        y_pred_svm = svm.predict(x_test_all)\n",
    "\n",
    "        f05_lda = fbeta_score(y_test_all, y_pred_lda, beta=0.5)\n",
    "        f05_svm = fbeta_score(y_test_all, y_pred_svm, beta=0.5)\n",
    "\n",
    "        score_dict_lda[test_cond].append(f05_lda)\n",
    "        score_dict_svm[test_cond].append(f05_svm)\n",
    "\n",
    "        # Trial-based accuracy; figured out += True works\n",
    "        correct_lda = 0\n",
    "        correct_svm = 0\n",
    "        for X_trial, y_trial, t_trial in test_trials:\n",
    "            pred_lda = lda.predict(X_trial)\n",
    "            pred_svm = svm.predict(X_trial)\n",
    "            if marker == 1009:\n",
    "                correct_lda += trial_correct_1009(y_trial, pred_lda, t_trial)\n",
    "                correct_svm += trial_correct_1009(y_trial, pred_svm, t_trial)\n",
    "            else:\n",
    "                correct_lda += trial_correct_1029(y_trial, pred_lda, t_trial)\n",
    "                correct_svm += trial_correct_1029(y_trial, pred_svm, t_trial)\n",
    "\n",
    "        total_trials = len(test_trials)\n",
    "        accuracy_dict_lda[test_cond].append(correct_lda / total_trials)\n",
    "        accuracy_dict_svm[test_cond].append(correct_svm / total_trials)\n",
    "\n",
    "        print(f\"Participant {p} | Test: {test_cond} | LDA F0.5: {f05_lda:.3f}, Acc: {correct_lda / total_trials:.3f}\")\n",
    "        print(f\"Participant {p} | Test: {test_cond} | SVM F0.5: {f05_svm:.3f}, Acc: {correct_svm / total_trials:.3f}\")\n",
    "\n",
    "# Group mean results\n",
    "for cond in conditions:\n",
    "    print(f\"{cond} | LDA Mean F0.5: {np.nanmean(score_dict_lda[cond]):.3f}, LDA Acc: {np.nanmean(accuracy_dict_lda[cond]):.3f}\")\n",
    "    print(f\"{cond} | SVM Mean F0.5: {np.nanmean(score_dict_svm[cond]):.3f}, SVM Acc: {np.nanmean(accuracy_dict_svm[cond]):.3f}\")\n",
    "\n",
    "rows = []\n",
    "for i, p in enumerate(participants):\n",
    "    for cond in conditions:\n",
    "        if i < len(score_dict_lda[cond]):\n",
    "            rows.append({\n",
    "                'Participant': p,\n",
    "                'Test_Condition': cond,\n",
    "                'LDA_F0.5': score_dict_lda[cond][i],\n",
    "                'LDA_Accuracy': accuracy_dict_lda[cond][i],\n",
    "                'SVM_F0.5': score_dict_svm[cond][i],\n",
    "                'SVM_Accuracy': accuracy_dict_svm[cond][i]\n",
    "            })\n",
    "\n",
    "### Convert to DataFrame and save ###\n",
    "df = pd.DataFrame(rows)\n",
    "if marker == 1009:\n",
    "    df.to_csv(f\"results\\\\cross_condition_results_first_{marker}.csv\", index=False)\n",
    "else:\n",
    "    df.to_csv(f\"results\\\\cross_condition_results_{marker}.csv\", index=False)\n",
    "print(\"Results saved to 'cross_condition_results_first_1009.csv'\")"
   ],
   "id": "7cb9c2ee5076ea68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant 1 | Test: Joystick | LDA F0.5: 0.252, Acc: 0.211\n",
      "Participant 1 | Test: Joystick | SVM F0.5: 0.273, Acc: 0.237\n",
      "Participant 1 | Test: Leaning | LDA F0.5: 0.256, Acc: 0.132\n",
      "Participant 1 | Test: Leaning | SVM F0.5: 0.264, Acc: 0.132\n",
      "Participant 1 | Test: Omnideck | LDA F0.5: 0.220, Acc: 0.054\n",
      "Participant 1 | Test: Omnideck | SVM F0.5: 0.173, Acc: 0.108\n",
      "Participant 1 | Test: Walking | LDA F0.5: 0.404, Acc: 0.184\n",
      "Participant 1 | Test: Walking | SVM F0.5: 0.327, Acc: 0.105\n",
      "Participant 2 | Test: Joystick | LDA F0.5: 0.196, Acc: 0.079\n",
      "Participant 2 | Test: Joystick | SVM F0.5: 0.339, Acc: 0.079\n",
      "Participant 2 | Test: Leaning | LDA F0.5: 0.396, Acc: 0.289\n",
      "Participant 2 | Test: Leaning | SVM F0.5: 0.473, Acc: 0.368\n",
      "Participant 2 | Test: Omnideck | LDA F0.5: 0.239, Acc: 0.184\n",
      "Participant 2 | Test: Omnideck | SVM F0.5: 0.346, Acc: 0.289\n",
      "Participant 2 | Test: Walking | LDA F0.5: 0.103, Acc: 0.026\n",
      "Participant 2 | Test: Walking | SVM F0.5: 0.214, Acc: 0.184\n",
      "Participant 3 | Test: Joystick | LDA F0.5: 0.211, Acc: 0.237\n",
      "Participant 3 | Test: Joystick | SVM F0.5: 0.316, Acc: 0.132\n",
      "Participant 3 | Test: Leaning | LDA F0.5: 0.375, Acc: 0.053\n",
      "Participant 3 | Test: Leaning | SVM F0.5: 0.377, Acc: 0.158\n",
      "Participant 3 | Test: Walking | LDA F0.5: 0.455, Acc: 0.211\n",
      "Participant 3 | Test: Walking | SVM F0.5: 0.388, Acc: 0.237\n",
      "File sub-P004_ses-Leaning1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Leaning2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Leaning1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Leaning2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Leaning1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Leaning2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking2_epochs_1029_epo.fif not found\n",
      "Participant 5 | Test: Joystick | LDA F0.5: 0.179, Acc: 0.184\n",
      "Participant 5 | Test: Joystick | SVM F0.5: 0.312, Acc: 0.263\n",
      "Participant 5 | Test: Leaning | LDA F0.5: 0.236, Acc: 0.105\n",
      "Participant 5 | Test: Leaning | SVM F0.5: 0.245, Acc: 0.211\n",
      "Participant 5 | Test: Omnideck | LDA F0.5: 0.434, Acc: 0.263\n",
      "Participant 5 | Test: Omnideck | SVM F0.5: 0.362, Acc: 0.342\n",
      "Participant 5 | Test: Walking | LDA F0.5: 0.343, Acc: 0.184\n",
      "Participant 5 | Test: Walking | SVM F0.5: 0.252, Acc: 0.211\n",
      "Participant 6 | Test: Joystick | LDA F0.5: 0.190, Acc: 0.184\n",
      "Participant 6 | Test: Joystick | SVM F0.5: 0.442, Acc: 0.316\n",
      "Participant 6 | Test: Leaning | LDA F0.5: 0.359, Acc: 0.316\n",
      "Participant 6 | Test: Leaning | SVM F0.5: 0.368, Acc: 0.237\n",
      "Participant 6 | Test: Omnideck | LDA F0.5: 0.333, Acc: 0.184\n",
      "Participant 6 | Test: Omnideck | SVM F0.5: 0.451, Acc: 0.263\n",
      "Participant 6 | Test: Walking | LDA F0.5: 0.371, Acc: 0.105\n",
      "Participant 6 | Test: Walking | SVM F0.5: 0.402, Acc: 0.184\n",
      "Participant 7 | Test: Omnideck | LDA F0.5: 0.288, Acc: 0.105\n",
      "Participant 7 | Test: Omnideck | SVM F0.5: 0.338, Acc: 0.132\n",
      "Participant 7 | Test: Walking | LDA F0.5: 0.433, Acc: 0.184\n",
      "Participant 7 | Test: Walking | SVM F0.5: 0.190, Acc: 0.211\n",
      "Participant 8 | Test: Joystick | LDA F0.5: 0.415, Acc: 0.263\n",
      "Participant 8 | Test: Joystick | SVM F0.5: 0.417, Acc: 0.237\n",
      "Participant 8 | Test: Leaning | LDA F0.5: 0.580, Acc: 0.342\n",
      "Participant 8 | Test: Leaning | SVM F0.5: 0.592, Acc: 0.395\n",
      "Participant 8 | Test: Omnideck | LDA F0.5: 0.450, Acc: 0.395\n",
      "Participant 8 | Test: Omnideck | SVM F0.5: 0.508, Acc: 0.289\n",
      "Participant 8 | Test: Walking | LDA F0.5: 0.533, Acc: 0.263\n",
      "Participant 8 | Test: Walking | SVM F0.5: 0.539, Acc: 0.263\n",
      "Participant 9 | Test: Joystick | LDA F0.5: 0.336, Acc: 0.132\n",
      "Participant 9 | Test: Joystick | SVM F0.5: 0.323, Acc: 0.158\n",
      "Participant 9 | Test: Leaning | LDA F0.5: 0.075, Acc: 0.053\n",
      "Participant 9 | Test: Leaning | SVM F0.5: 0.339, Acc: 0.289\n",
      "Participant 9 | Test: Omnideck | LDA F0.5: 0.351, Acc: 0.237\n",
      "Participant 9 | Test: Omnideck | SVM F0.5: 0.310, Acc: 0.237\n",
      "Participant 9 | Test: Walking | LDA F0.5: 0.153, Acc: 0.211\n",
      "Participant 9 | Test: Walking | SVM F0.5: 0.272, Acc: 0.184\n",
      "Participant 10 | Test: Joystick | LDA F0.5: 0.405, Acc: 0.316\n",
      "Participant 10 | Test: Joystick | SVM F0.5: 0.531, Acc: 0.368\n",
      "Participant 10 | Test: Leaning | LDA F0.5: 0.581, Acc: 0.447\n",
      "Participant 10 | Test: Leaning | SVM F0.5: 0.634, Acc: 0.447\n",
      "Participant 10 | Test: Omnideck | LDA F0.5: 0.479, Acc: 0.263\n",
      "Participant 10 | Test: Omnideck | SVM F0.5: 0.553, Acc: 0.395\n",
      "Participant 10 | Test: Walking | LDA F0.5: 0.454, Acc: 0.184\n",
      "Participant 10 | Test: Walking | SVM F0.5: 0.478, Acc: 0.132\n",
      "Participant 11 | Test: Joystick | LDA F0.5: 0.483, Acc: 0.237\n",
      "Participant 11 | Test: Joystick | SVM F0.5: 0.523, Acc: 0.263\n",
      "Participant 11 | Test: Leaning | LDA F0.5: 0.362, Acc: 0.211\n",
      "Participant 11 | Test: Leaning | SVM F0.5: 0.429, Acc: 0.211\n",
      "Participant 11 | Test: Omnideck | LDA F0.5: 0.581, Acc: 0.421\n",
      "Participant 11 | Test: Omnideck | SVM F0.5: 0.513, Acc: 0.263\n",
      "Participant 11 | Test: Walking | LDA F0.5: 0.423, Acc: 0.211\n",
      "Participant 11 | Test: Walking | SVM F0.5: 0.414, Acc: 0.289\n",
      "Participant 12 | Test: Joystick | LDA F0.5: 0.404, Acc: 0.289\n",
      "Participant 12 | Test: Joystick | SVM F0.5: 0.482, Acc: 0.316\n",
      "Participant 12 | Test: Leaning | LDA F0.5: 0.450, Acc: 0.263\n",
      "Participant 12 | Test: Leaning | SVM F0.5: 0.406, Acc: 0.368\n",
      "Participant 12 | Test: Omnideck | LDA F0.5: 0.280, Acc: 0.158\n",
      "Participant 12 | Test: Omnideck | SVM F0.5: 0.417, Acc: 0.368\n",
      "Participant 12 | Test: Walking | LDA F0.5: 0.279, Acc: 0.211\n",
      "Participant 12 | Test: Walking | SVM F0.5: 0.360, Acc: 0.316\n",
      "Participant 13 | Test: Joystick | LDA F0.5: 0.203, Acc: 0.105\n",
      "Participant 13 | Test: Joystick | SVM F0.5: 0.198, Acc: 0.158\n",
      "Participant 13 | Test: Leaning | LDA F0.5: 0.207, Acc: 0.158\n",
      "Participant 13 | Test: Leaning | SVM F0.5: 0.280, Acc: 0.158\n",
      "Participant 13 | Test: Omnideck | LDA F0.5: 0.053, Acc: 0.000\n",
      "Participant 13 | Test: Omnideck | SVM F0.5: 0.271, Acc: 0.237\n",
      "Participant 14 | Test: Joystick | LDA F0.5: 0.515, Acc: 0.132\n",
      "Participant 14 | Test: Joystick | SVM F0.5: 0.517, Acc: 0.263\n",
      "Participant 14 | Test: Leaning | LDA F0.5: 0.334, Acc: 0.237\n",
      "Participant 14 | Test: Leaning | SVM F0.5: 0.382, Acc: 0.132\n",
      "Participant 14 | Test: Omnideck | LDA F0.5: 0.512, Acc: 0.368\n",
      "Participant 14 | Test: Omnideck | SVM F0.5: 0.540, Acc: 0.316\n",
      "Participant 14 | Test: Walking | LDA F0.5: 0.552, Acc: 0.263\n",
      "Participant 14 | Test: Walking | SVM F0.5: 0.691, Acc: 0.395\n",
      "Joystick | LDA Mean F0.5: 0.316, LDA Acc: 0.197\n",
      "Joystick | SVM Mean F0.5: 0.389, SVM Acc: 0.232\n",
      "Leaning | LDA Mean F0.5: 0.351, LDA Acc: 0.217\n",
      "Leaning | SVM Mean F0.5: 0.399, SVM Acc: 0.259\n",
      "Omnideck | LDA Mean F0.5: 0.352, LDA Acc: 0.219\n",
      "Omnideck | SVM Mean F0.5: 0.399, SVM Acc: 0.270\n",
      "Walking | LDA Mean F0.5: 0.375, LDA Acc: 0.186\n",
      "Walking | SVM Mean F0.5: 0.377, SVM Acc: 0.226\n",
      "Results saved to 'cross_condition_results_first_1009.csv'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Walking --> Omnideck Transfer (and vice versa)",
   "id": "e352851e0a6c75ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T10:25:59.897230Z",
     "start_time": "2025-07-16T10:25:31.258328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transfer learning from training on Omnideck and testing on real walking and the other way round\n",
    "marker = 1009\n",
    "results = []\n",
    "participants = list(range(1, 15))\n",
    "excluded = {\n",
    "    (3, 'Omnideck'), (7, 'Leaning'), (7, 'Joystick'), (13, 'Walking')\n",
    "}\n",
    "\n",
    "for p in participants:\n",
    "    for train_cond, test_cond in [('Walking', 'Omnideck'), ('Omnideck', 'Walking')]:\n",
    "        if (p, train_cond) in excluded or (p, test_cond) in excluded or p == 4:\n",
    "            results.append((p, train_cond, test_cond, np.nan, np.nan, np.nan, np.nan))\n",
    "            continue\n",
    "\n",
    "        path = f'epochs\\\\P{p:03d}\\\\'\n",
    "        x_train, y_train = [], []\n",
    "        x_test, y_test = [], []\n",
    "        test_trials = []\n",
    "\n",
    "        for cond, store in [(train_cond, 'train'), (test_cond, 'test')]:\n",
    "            for i in range(1, 3):\n",
    "                if p == 13 and cond == 'Walking' and i == 2:\n",
    "                    continue\n",
    "                if marker == 1009:\n",
    "                    filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_first_{marker}_autoreject_epo.fif'\n",
    "                else:\n",
    "                    filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_{marker}_autoreject_epo.fif'\n",
    "                try:\n",
    "                    epochs = mne.read_epochs(path + filename, verbose='error')\n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "                epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "\n",
    "                if marker == 1009:\n",
    "                    start_times = np.arange(-6, -0.999, 0.125)\n",
    "                    epochs.crop(tmin=-6, tmax=0)\n",
    "                else:\n",
    "                    start_times = np.arange(-5, 0.001, 0.125)\n",
    "                    epochs.crop(tmin=-5, tmax=1)\n",
    "                epochs.resample(sfreq=10)\n",
    "\n",
    "                for j in range(len(epochs)):\n",
    "                    epoch = mrcp(epochs[j])\n",
    "                    raw = mne.io.RawArray(epoch.get_data(), epochs.info)\n",
    "                    sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "                    X = sliding_window.get_data()\n",
    "                    X_features = X.reshape(X.shape[0], -1)\n",
    "                    norms = np.linalg.norm(X_features, axis=1, keepdims=True)\n",
    "                    norms[norms == 0] = 1.0\n",
    "                    X_features = X_features / norms\n",
    "                    if marker == 1009:\n",
    "                        y = [1 if -1.875 <= t <= 0 else 0 for t in start_times]\n",
    "                    else:\n",
    "                        y = [1 if -0.875 <= t <= 1 else 0 for t in start_times]\n",
    "                    y = np.array(y)\n",
    "\n",
    "                    if store == 'train':\n",
    "                        x_train.append(X_features)\n",
    "                        y_train.append(y)\n",
    "                    else:\n",
    "                        x_test.append(X_features)\n",
    "                        y_test.append(y)\n",
    "                        test_trials.append((X_features, y, start_times))\n",
    "\n",
    "        #if not x_train or not x_test:\n",
    "        #    results.append((p, train_cond, test_cond, np.nan, np.nan, np.nan, np.nan))\n",
    "        #    continue\n",
    "        x_train = np.concatenate(x_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "        x_test_all = np.concatenate(x_test, axis=0)\n",
    "        y_test_all = np.concatenate(y_test, axis=0)\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "        svm = SVC(kernel='rbf', probability=True)\n",
    "        f05 = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "        lda.fit(x_train, y_train)\n",
    "        svm.fit(x_train, y_train)\n",
    "\n",
    "        y_pred_lda = lda.predict(x_test_all)\n",
    "        y_pred_svm = svm.predict(x_test_all)\n",
    "\n",
    "        f05_lda = fbeta_score(y_test_all, y_pred_lda, beta=0.5)\n",
    "        f05_svm = fbeta_score(y_test_all, y_pred_svm, beta=0.5)\n",
    "\n",
    "        # Trial-based accuracy\n",
    "        correct_lda = 0\n",
    "        correct_svm = 0\n",
    "        for X_trial, y_trial, t_trial in test_trials:\n",
    "            pred_lda = lda.predict(X_trial)\n",
    "            pred_svm = svm.predict(X_trial)\n",
    "            if marker == 1009:\n",
    "                correct_lda += trial_correct_1009(y_trial, pred_lda, t_trial)\n",
    "                correct_svm += trial_correct_1009(y_trial, pred_svm, t_trial)\n",
    "            else:\n",
    "                correct_lda += trial_correct_1029(y_trial, pred_lda, t_trial)\n",
    "                correct_svm += trial_correct_1029(y_trial, pred_svm, t_trial)\n",
    "\n",
    "        total_trials = len(test_trials)\n",
    "        acc_lda = correct_lda / total_trials\n",
    "        acc_svm = correct_svm / total_trials\n",
    "\n",
    "        results.append((p, train_cond, test_cond, f05_lda, acc_lda, f05_svm, acc_svm))\n",
    "\n",
    "        print(f\"P{p:02d} | Train: {train_cond} → Test: {test_cond} | \"\n",
    "              f\"LDA F0.5: {f05_lda:.3f}, Acc: {acc_lda:.3f} | \"\n",
    "              f\"SVM F0.5: {f05_svm:.3f}, Acc: {acc_svm:.3f}\")\n",
    "\n",
    "# Optional: print group means\n",
    "for direction in [('Walking', 'Omnideck'), ('Omnideck', 'Walking')]:\n",
    "    f05_lda_all = [r[3] for r in results if (r[1], r[2]) == direction and not np.isnan(r[3])]\n",
    "    acc_lda_all = [r[4] for r in results if (r[1], r[2]) == direction and not np.isnan(r[4])]\n",
    "    f05_svm_all = [r[5] for r in results if (r[1], r[2]) == direction and not np.isnan(r[5])]\n",
    "    acc_svm_all = [r[6] for r in results if (r[1], r[2]) == direction and not np.isnan(r[6])]\n",
    "\n",
    "    print(f\"\\nTrain: {direction[0]} → Test: {direction[1]}\")\n",
    "    print(f\"LDA  Mean F0.5: {np.mean(f05_lda_all):.3f} | Mean Accuracy: {np.mean(acc_lda_all):.3f}\")\n",
    "    print(f\"SVM  Mean F0.5: {np.mean(f05_svm_all):.3f} | Mean Accuracy: {np.mean(acc_svm_all):.3f}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_results = pd.DataFrame(results, columns=[\n",
    "    'Participant', 'Train_Condition', 'Test_Condition',\n",
    "    'LDA_F0.5', 'LDA_Accuracy', 'SVM_F0.5', 'SVM_Accuracy'\n",
    "])\n",
    "\n",
    "# Save to CSV\n",
    "if marker == 1009:\n",
    "    df_results.to_csv(f'results\\\\transfer_learning_omideck_walking_first_{marker}_results.csv', index=False)\n",
    "else:\n",
    "    df_results.to_csv(f'results\\\\transfer_learning_omideck_walking_{marker}_results.csv', index=False)\n",
    "print(\"Results saved to 'transfer_learning_results.csv'\")\n"
   ],
   "id": "e099c8906bf26aa6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01 | Train: Walking → Test: Omnideck | LDA F0.5: 0.197, Acc: 0.074 | SVM F0.5: 0.194, Acc: 0.185\n",
      "P01 | Train: Omnideck → Test: Walking | LDA F0.5: 0.158, Acc: 0.091 | SVM F0.5: 0.239, Acc: 0.152\n",
      "P02 | Train: Walking → Test: Omnideck | LDA F0.5: 0.169, Acc: 0.030 | SVM F0.5: 0.265, Acc: 0.152\n",
      "P02 | Train: Omnideck → Test: Walking | LDA F0.5: 0.245, Acc: 0.088 | SVM F0.5: 0.338, Acc: 0.059\n",
      "P05 | Train: Walking → Test: Omnideck | LDA F0.5: 0.163, Acc: 0.029 | SVM F0.5: 0.104, Acc: 0.029\n",
      "P05 | Train: Omnideck → Test: Walking | LDA F0.5: 0.183, Acc: 0.133 | SVM F0.5: 0.109, Acc: 0.033\n",
      "P06 | Train: Walking → Test: Omnideck | LDA F0.5: 0.293, Acc: 0.212 | SVM F0.5: 0.207, Acc: 0.121\n",
      "P06 | Train: Omnideck → Test: Walking | LDA F0.5: 0.184, Acc: 0.250 | SVM F0.5: 0.205, Acc: 0.125\n",
      "P07 | Train: Walking → Test: Omnideck | LDA F0.5: 0.201, Acc: 0.056 | SVM F0.5: 0.280, Acc: 0.028\n",
      "P07 | Train: Omnideck → Test: Walking | LDA F0.5: 0.270, Acc: 0.027 | SVM F0.5: 0.215, Acc: 0.081\n",
      "P08 | Train: Walking → Test: Omnideck | LDA F0.5: 0.335, Acc: 0.200 | SVM F0.5: 0.288, Acc: 0.229\n",
      "P08 | Train: Omnideck → Test: Walking | LDA F0.5: 0.238, Acc: 0.059 | SVM F0.5: 0.251, Acc: 0.176\n",
      "P09 | Train: Walking → Test: Omnideck | LDA F0.5: 0.448, Acc: 0.257 | SVM F0.5: 0.414, Acc: 0.286\n",
      "P09 | Train: Omnideck → Test: Walking | LDA F0.5: 0.322, Acc: 0.111 | SVM F0.5: 0.307, Acc: 0.194\n",
      "P10 | Train: Walking → Test: Omnideck | LDA F0.5: 0.188, Acc: 0.135 | SVM F0.5: 0.148, Acc: 0.108\n",
      "P10 | Train: Omnideck → Test: Walking | LDA F0.5: 0.280, Acc: 0.143 | SVM F0.5: 0.058, Acc: 0.086\n",
      "P11 | Train: Walking → Test: Omnideck | LDA F0.5: 0.173, Acc: 0.094 | SVM F0.5: 0.337, Acc: 0.094\n",
      "P11 | Train: Omnideck → Test: Walking | LDA F0.5: 0.296, Acc: 0.158 | SVM F0.5: 0.330, Acc: 0.105\n",
      "P12 | Train: Walking → Test: Omnideck | LDA F0.5: 0.240, Acc: 0.273 | SVM F0.5: 0.153, Acc: 0.045\n",
      "P12 | Train: Omnideck → Test: Walking | LDA F0.5: 0.225, Acc: 0.000 | SVM F0.5: 0.408, Acc: 0.091\n",
      "P14 | Train: Walking → Test: Omnideck | LDA F0.5: 0.320, Acc: 0.038 | SVM F0.5: 0.346, Acc: 0.192\n",
      "P14 | Train: Omnideck → Test: Walking | LDA F0.5: 0.470, Acc: 0.207 | SVM F0.5: 0.575, Acc: 0.517\n",
      "\n",
      "Train: Walking → Test: Omnideck\n",
      "LDA  Mean F0.5: 0.248 | Mean Accuracy: 0.127\n",
      "SVM  Mean F0.5: 0.249 | Mean Accuracy: 0.133\n",
      "\n",
      "Train: Omnideck → Test: Walking\n",
      "LDA  Mean F0.5: 0.261 | Mean Accuracy: 0.115\n",
      "SVM  Mean F0.5: 0.276 | Mean Accuracy: 0.147\n",
      "Results saved to 'transfer_learning_results.csv'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Leftover Code from Cleanup",
   "id": "e6a87b050f931d44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Make i a function with a parameter that can be 'trial', 'condition', 'subject' or 'global' that runs the classification or just assembles the data in given the scope\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "from sklearn.svm import SVC\n",
    "score_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "score_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "conditions = ['Joystick', 'Leaning', 'Omnideck', 'Walking']\n",
    "for cond in conditions:\n",
    "    for p in range(1,15):\n",
    "        if p == 4 or p == 7 or p == 13:\n",
    "            score_dict_lda[cond].append(np.nan)\n",
    "            score_dict_svm[cond].append(np.nan)\n",
    "            continue\n",
    "        if p == 3 and cond == 'Omnideck':\n",
    "            score_dict_lda[cond].append(np.nan)\n",
    "            score_dict_svm[cond].append(np.nan)\n",
    "            continue\n",
    "        path = f'epochs\\\\P{p:03d}\\\\'\n",
    "        i = 1\n",
    "        while i < 3:\n",
    "            filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_1029_epo.fif'\n",
    "            epochs = mne.read_epochs(path+filename)\n",
    "            epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "            ar = AutoReject(n_jobs=8, verbose=False)\n",
    "            epochs = ar.fit_transform(epochs)\n",
    "            start_times = np.arange(-6, 0.001, 0.125)\n",
    "            nr_epochs = len(epochs)\n",
    "            epochs.crop(tmin=-6, tmax=1)\n",
    "            epochs.resample(sfreq=10)\n",
    "\n",
    "            for j in range(len(epochs)):\n",
    "                epoch = mrcp(epochs[j])\n",
    "                raw = mne.io.RawArray(epoch.get_data(), epochs.info)\n",
    "                sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "                X = sliding_window.get_data()\n",
    "                X_features = X.reshape(X.shape[0], -1)\n",
    "                norms = np.linalg.norm(X_features, axis=1, keepdims=True)\n",
    "                norms[norms == 0] = 1.0  # prevent division by zero\n",
    "                X_features = X_features / norms\n",
    "                y = []\n",
    "                for t in start_times:\n",
    "                    if t < -0.5:\n",
    "                        y.append(0)\n",
    "                    elif t > 1:\n",
    "                        y.append(0)\n",
    "                    else:\n",
    "                        y.append(1)\n",
    "                y = np.array(y)\n",
    "                if i == 1 and j == 0:\n",
    "                    x_combined = X_features\n",
    "                    y_combined = y\n",
    "                else:\n",
    "                    x_combined = np.concatenate([x_combined, X_features], axis=0)\n",
    "                    y_combined = np.concatenate([y_combined, y], axis=0)\n",
    "            i += 1\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "        svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "        # Stratified 5-fold cross-validation\n",
    "        cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "        f05_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "        # Cross-validation scoring (you can change 'accuracy' to 'roc_auc', etc.)\n",
    "        scores_lda = cross_val_score(lda, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "        scores_svm = cross_val_score(svm, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "        score_dict_lda[cond].append(scores_lda.mean())\n",
    "        score_dict_svm[cond].append(scores_svm.mean())\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean LDA F0.5 Score:\", scores_lda.mean())\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean SVM F0.5 Score:\", scores_svm.mean())\n",
    "for cond in conditions:\n",
    "    print(f\"{cond} Mean F0.5 Score:\", np.nanmean(np.array(score_dict_lda[cond])))\n",
    "    print(f\"{cond} Mean F0.5 Score:\", np.nanmean(np.array(score_dict_svm[cond])))\n"
   ],
   "id": "bfaa846c58200971"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import mne\n",
    "from autoreject import AutoReject\n",
    "\n",
    "score_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "score_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "\n",
    "conditions = ['Joystick', 'Leaning', 'Omnideck', 'Walking']\n",
    "for cond in conditions:\n",
    "    for p in range(1, 15):\n",
    "        if p in [4] or (p == 7 and cond == 'Leaning') or (p == 7 and cond == 'Joystick'):\n",
    "            score_dict_lda[cond].append(np.nan)\n",
    "            score_dict_svm[cond].append(np.nan)\n",
    "            accuracy_dict_lda[cond].append(np.nan)\n",
    "            accuracy_dict_svm[cond].append(np.nan)\n",
    "            continue\n",
    "\n",
    "        path = f'epochs\\\\P{p:03d}\\\\'\n",
    "        i = 1\n",
    "        x_combined = []\n",
    "        y_combined = []\n",
    "        trial_data = []\n",
    "\n",
    "        while i < 3:\n",
    "            # P13 only has one walking condition\n",
    "            if (p == 13 and cond == 'Walking' and i == 2) or (p == 3 and cond == 'Omnideck' and i == 2):\n",
    "                i+=1\n",
    "                continue\n",
    "            filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_first_1009_epo.fif'      # Change to 1029\n",
    "            epochs = mne.read_epochs(path + filename)\n",
    "            epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "            ar = AutoReject(n_jobs=8, verbose=False)\n",
    "            epochs = ar.fit_transform(epochs)\n",
    "            # For 1029: -5, 0.0001; For 1009: -6, -0.999\n",
    "            start_times = np.arange(-6, -0.999, 0.125)\n",
    "            epochs.crop(tmin=-6, tmax=0)\n",
    "            epochs.resample(sfreq=10)\n",
    "\n",
    "            for j in range(len(epochs)):\n",
    "                epoch = mrcp(epochs[j])\n",
    "                raw = mne.io.RawArray(epoch.get_data(), epochs.info)\n",
    "                sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "                X = sliding_window.get_data()\n",
    "                X_features = X.reshape(X.shape[0], -1)\n",
    "                norms = np.linalg.norm(X_features, axis=1, keepdims=True)\n",
    "                norms[norms == 0] = 1.0\n",
    "                X_features = X_features / norms\n",
    "                y = []\n",
    "                for t in start_times:\n",
    "                    # For 1029: -0.875; For 1009: -1.87\n",
    "                    if t < -1.875:\n",
    "                        y.append(0)\n",
    "                    elif t > 0:\n",
    "                        y.append(0)\n",
    "                    else:\n",
    "                        y.append(1)\n",
    "                y = np.array(y)\n",
    "\n",
    "                x_combined.append(X_features)\n",
    "                y_combined.append(y)\n",
    "                trial_data.append((X_features, y, start_times))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        x_combined = np.concatenate(x_combined, axis=0)\n",
    "        y_combined = np.concatenate(y_combined, axis=0)\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "        svm = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        f05_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "        scores_lda = cross_val_score(lda, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "        scores_svm = cross_val_score(svm, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "\n",
    "        score_dict_lda[cond].append(scores_lda.mean())\n",
    "        score_dict_svm[cond].append(scores_svm.mean())\n",
    "\n",
    "        # Fit classifiers for trial-wise accuracy\n",
    "        lda.fit(x_combined, y_combined)\n",
    "        svm.fit(x_combined, y_combined)\n",
    "\n",
    "        correct_trials_lda = 0\n",
    "        correct_trials_svm = 0\n",
    "\n",
    "        for X_trial, y_trial, t_trial in trial_data:\n",
    "            y_pred_lda = lda.predict(X_trial)\n",
    "            y_pred_svm = svm.predict(X_trial)\n",
    "\n",
    "            # Accuracy\n",
    "            if trial_correct(y_trial, y_pred_lda, t_trial):\n",
    "                correct_trials_lda += 1\n",
    "            if trial_correct(y_trial, y_pred_svm, t_trial):\n",
    "                correct_trials_svm += 1\n",
    "\n",
    "        total_trials = len(trial_data)\n",
    "        accuracy_dict_lda[cond].append(correct_trials_lda / total_trials)\n",
    "        accuracy_dict_svm[cond].append(correct_trials_svm / total_trials)\n",
    "\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean LDA F0.5 Score: {scores_lda.mean():.3f} | Accuracy: {correct_trials_lda / total_trials:.3f}\")\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean SVM F0.5 Score: {scores_svm.mean():.3f} | Accuracy: {correct_trials_svm / total_trials:.3f}\")\n",
    "\n",
    "# Print group means\n",
    "for cond in conditions:\n",
    "    print(f\"{cond} | LDA Mean F0.5 Score: {np.nanmean(score_dict_lda[cond]):.3f} | LDA Accuracy: {np.nanmean(accuracy_dict_lda[cond]):.3f}\")\n",
    "    print(f\"{cond} | SVM Mean F0.5 Score: {np.nanmean(score_dict_svm[cond]):.3f} | SVM Accuracy: {np.nanmean(accuracy_dict_svm[cond]):.3f}\")\n"
   ],
   "id": "b6c181852c55a46e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
