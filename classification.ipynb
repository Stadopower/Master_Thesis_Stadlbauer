{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-22T07:06:47.724102Z",
     "start_time": "2025-07-22T07:06:45.130982Z"
    }
   },
   "source": [
    "#Spliting train and test correctly (GPT)\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import pyxdf\n",
    "import pandas as pd\n",
    "import re\n",
    "import mne\n",
    "from sklearn.decomposition import fastica\n",
    "from pyprep import PrepPipeline, NoisyChannels\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import matplotlib\n",
    "from mne_icalabel import label_components\n",
    "from autoreject import AutoReject\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, KFold\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib qt\n",
    "matplotlib.use('Qt5Agg')\n",
    "mne.set_log_level('warning')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T07:55:25.265566Z",
     "start_time": "2025-07-22T07:55:25.253990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# some function to make the end result more readable:\n",
    "#filename has to be the entire path to the file so \"data//P101//filename\"\n",
    "\n",
    "def get_data(filename, pilot=False):    # Pilot = True for all pilots except Pilot117\n",
    "    print('Reading data')\n",
    "\n",
    "    # Because of the software switch there are now 3 ACC channels and one Marker channel\n",
    "    nr_non_eeg = 4\n",
    "    if pilot:\n",
    "        nr_non_eeg = 3\n",
    "\n",
    "    # Reading in the xdf files and extracting the marker and eeg streams\n",
    "    streams, fileheader = pyxdf.load_xdf(filename, select_streams=[{'type': 'EEG'}, {'name':'LSL4Unity.OmnideckWaiterVR'}] , synchronize_clocks=False)\n",
    "    marker_stream = next(s for s in streams if 'LSL4Unity.OmnideckWaiterVR' in s['info']['name'][0])\n",
    "    eeg_stream = next(s for s in streams if \"EEG\" in s['info']['type'][0])\n",
    "    eeg_data = np.array(eeg_stream['time_series']).T\n",
    "    #eeg_timestamps = np.array(eeg_stream['time_stamps'])\n",
    "    sfreq = float(eeg_stream['info']['nominal_srate'][0])\n",
    "\n",
    "    # Collection all ch names and renaming TP9, TP10\n",
    "    ch_names = []\n",
    "    for ch in eeg_stream['info']['desc'][0]['channels'][0]['channel']:\n",
    "        if ch['label'][0] == 'TP10':\n",
    "            ch_names.append('FCz')\n",
    "        elif ch['label'][0] == 'TP9':\n",
    "            ch_names.append('Fpz')\n",
    "        elif ch['label'][0] == 'FPz':\n",
    "            ch_names.append('Fpz')\n",
    "        else:\n",
    "            ch_names.append(ch['label'][0])\n",
    "    info = mne.create_info(\n",
    "        ch_names=ch_names[:-nr_non_eeg],\n",
    "        sfreq=sfreq,\n",
    "        ch_types='eeg'\n",
    "    )\n",
    "    raw = mne.io.RawArray(eeg_data[:-nr_non_eeg]/10e5, info)\n",
    "\n",
    "    # Creating the Montage\n",
    "    montage = mne.channels.make_standard_montage('standard_1020')\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    # Calculating the event samples for the annotations\n",
    "    event_samples = (marker_stream['time_stamps'] - eeg_stream['time_stamps'][0])*sfreq\n",
    "    event_samples = event_samples.astype(int)\n",
    "    event_labels = [int(marker[0]) for marker in marker_stream['time_series']]\n",
    "\n",
    "\n",
    "    annotations = mne.Annotations(onset=event_samples / sfreq,\n",
    "                                  duration=[0] * len(event_samples),  # Instantaneous events\n",
    "                                  description=list(event_labels))\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    return raw, marker_stream, event_samples\n",
    "\n",
    "#apply a notch filter at 50hz and filter between 0.01 and 40Hz. Filter above 1Hz is applied when creating the epochs\n",
    "def filter_data(raw):\n",
    "    # Notch Filter at 50 Hz\n",
    "    raw = raw.notch_filter(50, method='fir', phase='zero',verbose=False)\n",
    "    # Filter data between 0.01 and 40 Hz\n",
    "    iir_params = dict(order=2, ftype='butter',verbose=False)\n",
    "    raw = raw.filter(l_freq=0.01, h_freq=40, method='iir', iir_params=iir_params, phase='zero', verbose=False)\n",
    "    return raw\n",
    "\n",
    "\n",
    "# making epochs around a specified marker, Applying 1Hz Highpass filter if epoch is used for ICA\n",
    "def get_epochs(raw: mne.io.Raw, marker_stream, event_samples , marker_id:int, tmin:int, tmax:int, preload=False, ica=True):\n",
    "    current_sfreq = raw.info[\"sfreq\"]\n",
    "    desired_sfreq = 128  # Hz\n",
    "    decim = np.round(current_sfreq / desired_sfreq).astype(int)\n",
    "    if ica:\n",
    "        iir_params = dict(order=2, ftype='butter',verbose=False)\n",
    "        raw = raw.copy()\n",
    "        raw = raw.filter(l_freq=1, h_freq=None, method='iir', iir_params=iir_params, phase='zero', verbose=False)\n",
    "    event_labels = [int(marker[0]) for marker in marker_stream['time_series']]\n",
    "    events = np.array([[sample, 0, label] for sample, label in zip(event_samples, event_labels)])\n",
    "    selected_events = events[events[:, 2] == marker_id]\n",
    "    epochs = mne.Epochs(raw, np.array(selected_events), event_id=int(marker_id),baseline=None, tmin=tmin, tmax=tmax, reject_by_annotation=False, verbose=False, preload=preload, decim=decim)\n",
    "    return epochs\n",
    "\n",
    "# Counts the markers and saves them in a file.\n",
    "def count_markers(marker_stream, match = False):\n",
    "    flat_list = [int(marker[0]) for marker in marker_stream['time_series']]\n",
    "    marker_count = {}\n",
    "    for marker in flat_list:\n",
    "        if marker in marker_count:\n",
    "            marker_count[marker] += 1\n",
    "        else:\n",
    "            marker_count[marker] = 1\n",
    "    marker_count = dict(sorted(marker_count.items()))\n",
    "    if match:\n",
    "        with open(f'markers\\\\{match}_markers.txt', 'w') as file:\n",
    "            for key, value in marker_count.items():\n",
    "                file.write(f\"{key}: {value}\\n\")\n",
    "    #return marker_count\n",
    "\n",
    "\n",
    "# load data, filter, epoch, ICA, average, plot\n",
    "def mrcp(epochs):\n",
    "    frontal_channels = ['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2']\n",
    "    iir_params = dict(order=2, ftype='butter')\n",
    "    epochs = epochs.filter(l_freq =0.1 ,h_freq=1, method='iir', iir_params=iir_params, phase='zero')\n",
    "    evoked = epochs.average()\n",
    "    evoked = evoked.pick(frontal_channels)\n",
    "    return evoked\n",
    "\n",
    "\n",
    "#adjust for 1009 and 1029\n",
    "def trial_correct_1009(y_true, y_pred, times):\n",
    "    correct_in_window = any(\n",
    "        (t >= -2.375 and t <= 1 and yt == 1 and yp == 1)\n",
    "        for t, yt, yp in zip(times, y_true, y_pred)\n",
    "    )\n",
    "    incorrect_before = any(\n",
    "        (t < -2.375 and yt == 0 and yp == 1)\n",
    "        for t, yt, yp in zip(times, y_true, y_pred)\n",
    "    )\n",
    "    return correct_in_window and not incorrect_before\n",
    "\n",
    "def trial_correct_1029(y_true, y_pred, times):\n",
    "    correct_in_window = any(\n",
    "        (t >= -1.375 and t <= 2 and yt == 1 and yp == 1)\n",
    "        for t, yt, yp in zip(times, y_true, y_pred)\n",
    "    )\n",
    "    incorrect_before = any(\n",
    "        (t < -1.375 and yt == 0 and yp == 1)\n",
    "        for t, yt, yp in zip(times, y_true, y_pred)\n",
    "    )\n",
    "    return correct_in_window and not incorrect_before"
   ],
   "id": "ccf3af989b620f6f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-22T12:19:28.397728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Required imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "\n",
    "# Your custom functions should be defined: mrcp, trial_correct_1009, trial_correct_1029\n",
    "\n",
    "# Split train and test correctly\n",
    "score_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "score_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "conditions = ['Joystick', 'Leaning', 'Omnideck', 'Walking']\n",
    "marker = 1029\n",
    "\n",
    "for cond in conditions:\n",
    "    for p in range(1, 15):\n",
    "        if p in [4] or (p == 7 and cond == 'Leaning') or (p == 7 and cond == 'Joystick') or (p == 3 and cond == 'Omnideck') or (p == 13 and cond == 'Walking'):\n",
    "            score_dict_lda[cond].append(np.nan)\n",
    "            score_dict_svm[cond].append(np.nan)\n",
    "            accuracy_dict_lda[cond].append(np.nan)\n",
    "            accuracy_dict_svm[cond].append(np.nan)\n",
    "            continue\n",
    "\n",
    "        path = f'epochs\\\\P{p:03d}\\\\'\n",
    "        i = 1\n",
    "        x_combined = []\n",
    "        y_combined = []\n",
    "        trial_data = []\n",
    "\n",
    "        # Initialize window error counters per participant\n",
    "        start_times = np.arange(-6, 0.001, 0.125) if marker == 1009 else np.arange(-5, 1.001, 0.125)\n",
    "        window_errors_lda_p = {cond: {t: 0 for t in start_times}}\n",
    "        window_errors_svm_p = {cond: {t: 0 for t in start_times}}\n",
    "\n",
    "        while i < 3:\n",
    "            filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_first_{marker}_epo.fif' if marker == 1009 else f'sub-P{p:03d}_ses-{cond}{i}_epochs_{marker}_epo.fif'\n",
    "            epochs = mne.read_epochs(path + filename)\n",
    "            epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "\n",
    "            if marker == 1009:\n",
    "                start_times = np.arange(-6, 0.001, 0.125)\n",
    "                epochs.crop(tmin=-6, tmax=1)\n",
    "            else:\n",
    "                start_times = np.arange(-5, 1.001, 0.125)\n",
    "                epochs.crop(tmin=-5, tmax=2)\n",
    "\n",
    "            epochs.resample(sfreq=10)\n",
    "\n",
    "            for j in range(len(epochs)):\n",
    "                epoch = mrcp(epochs[j])\n",
    "                raw = mne.io.RawArray(epoch.get_data(), epochs.info)\n",
    "                sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "                X = sliding_window.get_data()\n",
    "                X_features = X.reshape(X.shape[0], -1)\n",
    "                norms = np.linalg.norm(X_features, axis=1, keepdims=True)\n",
    "                norms[norms == 0] = 1.0\n",
    "                X_features = X_features / norms\n",
    "\n",
    "                y = []\n",
    "                for t in start_times:\n",
    "                    if marker == 1009:\n",
    "                        y.append(1 if -2.375 <= t <= 1 else 0)\n",
    "                    else:\n",
    "                        y.append(1 if -1.375 <= t <= 2 else 0)\n",
    "                y = np.array(y)\n",
    "\n",
    "                x_combined.append(X_features)\n",
    "                y_combined.append(y)\n",
    "                trial_data.append((X_features, y, start_times))\n",
    "            i += 1\n",
    "\n",
    "        x_combined = np.concatenate(x_combined, axis=0)\n",
    "        y_combined = np.concatenate(y_combined, axis=0)\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "        svm = SVC(kernel='rbf', probability=True)\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        f05_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "        scores_lda = cross_val_score(lda, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "        scores_svm = cross_val_score(svm, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "\n",
    "        score_dict_lda[cond].append(scores_lda.mean())\n",
    "        score_dict_svm[cond].append(scores_svm.mean())\n",
    "\n",
    "        ### Start of Accuracy Evaluation ###\n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "        accuracies_lda = []\n",
    "        accuracies_svm = []\n",
    "        fold_all_probs = []\n",
    "        fold_all_times = []\n",
    "\n",
    "        if 'window_errors_lda' not in locals():\n",
    "            window_errors_lda = {cond: {t: 0 for t in start_times} for cond in conditions}\n",
    "        if 'window_errors_svm' not in locals():\n",
    "            window_errors_svm = {cond: {t: 0 for t in start_times} for cond in conditions}\n",
    "\n",
    "        for train_idx, test_idx in kf.split(trial_data):\n",
    "            train_trials = [trial_data[i] for i in train_idx]\n",
    "            test_trials = [trial_data[i] for i in test_idx]\n",
    "\n",
    "            X_train = np.concatenate([X for X, y, t in train_trials], axis=0)\n",
    "            y_train = np.concatenate([y for X, y, t in train_trials], axis=0)\n",
    "\n",
    "            lda.fit(X_train, y_train)\n",
    "            svm.fit(X_train, y_train)\n",
    "\n",
    "            correct_lda = 0\n",
    "            correct_svm = 0\n",
    "            all_probs = []\n",
    "            all_times = []\n",
    "\n",
    "            for X_trial, y_trial, t_trial in test_trials:\n",
    "                y_pred_lda = lda.predict(X_trial)\n",
    "                y_pred_svm = svm.predict(X_trial)\n",
    "                probs = svm.predict_proba(X_trial)[:, 1]\n",
    "\n",
    "                all_probs.append(probs)\n",
    "                all_times.append(t_trial)\n",
    "\n",
    "                for true_label, pred_label, time in zip(y_trial, y_pred_lda, t_trial):\n",
    "                    if true_label != pred_label:\n",
    "                        window_errors_lda_p[cond][time] += 1\n",
    "                for true_label, pred_label, time in zip(y_trial, y_pred_svm, t_trial):\n",
    "                    if true_label != pred_label:\n",
    "                        window_errors_svm_p[cond][time] += 1\n",
    "\n",
    "                if marker == 1009:\n",
    "                    if trial_correct_1009(y_trial, y_pred_lda, t_trial):\n",
    "                        correct_lda += 1\n",
    "                    if trial_correct_1009(y_trial, y_pred_svm, t_trial):\n",
    "                        correct_svm += 1\n",
    "                else:\n",
    "                    if trial_correct_1029(y_trial, y_pred_lda, t_trial):\n",
    "                        correct_lda += 1\n",
    "                    if trial_correct_1029(y_trial, y_pred_svm, t_trial):\n",
    "                        correct_svm += 1\n",
    "\n",
    "            accuracies_lda.append(correct_lda / len(test_trials))\n",
    "            accuracies_svm.append(correct_svm / len(test_trials))\n",
    "            fold_all_probs.extend(all_probs)\n",
    "            fold_all_times.extend(all_times)\n",
    "\n",
    "        accuracy_dict_lda[cond].append(np.mean(accuracies_lda))\n",
    "        accuracy_dict_svm[cond].append(np.mean(accuracies_svm))\n",
    "\n",
    "        # === Plot average SVM probability across all folds ===\n",
    "        fold_all_probs = np.array(fold_all_probs)\n",
    "        fold_all_times = np.array(fold_all_times)\n",
    "\n",
    "        if not np.all([np.array_equal(fold_all_times[0], t) for t in fold_all_times]):\n",
    "            print(f\"Time misalignment warning | P{p} | Condition: {cond}\")\n",
    "            continue\n",
    "\n",
    "        mean_probs = np.nanmean(fold_all_probs, axis=0)\n",
    "        stderr_probs = np.nanstd(fold_all_probs, axis=0) / np.sqrt(fold_all_probs.shape[0])\n",
    "        mean_time = fold_all_times[0]\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(mean_time, mean_probs, label='Mean SVM Prob(class=1)', color='royalblue')\n",
    "        plt.fill_between(mean_time, mean_probs - stderr_probs, mean_probs + stderr_probs,\n",
    "                         color='lightblue', alpha=0.4, label='± SE')\n",
    "        plt.axvline(x=-2.375 if marker == 1009 else -1.375, color='black', linestyle='--', label='Movement Threshold')\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Predicted Probability\")\n",
    "        plt.title(f\"SVM Avg Probabilities | P{p:02d} | Condition: {cond}\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plot_dir = f\"results\\\\avg_prob_plots\\\\{marker}\"\n",
    "        os.makedirs(plot_dir, exist_ok=True)\n",
    "        plt.savefig(f\"{plot_dir}\\\\P{p:03d}_{cond}_avg_probabilities.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Save window error counts\n",
    "        rows = []\n",
    "        for time in sorted(window_errors_lda_p[cond].keys()):\n",
    "            rows.append({\n",
    "                \"Participant\": p,\n",
    "                \"Condition\": cond,\n",
    "                \"Time\": time,\n",
    "                \"LDA_Errors\": window_errors_lda_p[cond][time],\n",
    "                \"SVM_Errors\": window_errors_svm_p[cond][time]\n",
    "            })\n",
    "\n",
    "        df_participant_errors = pd.DataFrame(rows)\n",
    "        error_dir = f\"results\\\\window_errors\\\\{marker}\"\n",
    "        os.makedirs(error_dir, exist_ok=True)\n",
    "        df_participant_errors.to_csv(f\"{error_dir}\\\\P{p:03d}_{cond}_window_errors.csv\", index=False)\n",
    "\n",
    "# Print group means\n",
    "for cond in conditions:\n",
    "    print(f\"{cond} | LDA Mean F0.5 Score: {np.nanmean(score_dict_lda[cond]):.3f} | LDA Accuracy: {np.nanmean(accuracy_dict_lda[cond]):.3f}\")\n",
    "    print(f\"{cond} | SVM Mean F0.5 Score: {np.nanmean(score_dict_svm[cond]):.3f} | SVM Accuracy: {np.nanmean(accuracy_dict_svm[cond]):.3f}\")\n",
    "\n",
    "# Save group results\n",
    "participants = list(range(0, 14))\n",
    "rows = []\n",
    "for cond in conditions:\n",
    "    for i, p in enumerate(participants):\n",
    "        row = {\n",
    "            \"Participant\": p+1,\n",
    "            \"Condition\": cond,\n",
    "            \"LDA_F0.5_Score\": score_dict_lda[cond][i],\n",
    "            \"SVM_F0.5_Score\": score_dict_svm[cond][i],\n",
    "            \"LDA_Accuracy\": accuracy_dict_lda[cond][i],\n",
    "            \"SVM_Accuracy\": accuracy_dict_svm[cond][i]\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "output_file = f\"results\\\\classification_results_single_cond_first_{marker}.csv\" if marker == 1009 else f\"results\\\\classification_results_single_cond_{marker}.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(\"Results saved to classification_results.csv\")\n"
   ],
   "id": "998770e53d4f6ff3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## In Condition Training and Testing\n",
    "\n",
    "Marker has to be selected manually, 1009 for the hand movement and 1029 for the start of VR movement marker\n"
   ],
   "id": "596aa5e69759c9ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T09:21:58.879600Z",
     "start_time": "2025-07-22T09:21:58.849360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Spliting train and test correctly\n",
    "score_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "score_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "conditions = ['Joystick', 'Leaning', 'Omnideck', 'Walking']\n",
    "marker = 1009\n",
    "for cond in conditions:\n",
    "    for p in range(1, 15):\n",
    "        if p in [4] or (p == 7 and cond == 'Leaning') or (p == 7 and cond == 'Joystick') or (p == 3 and cond == 'Omnideck') or (p == 13 and cond == 'Walking'):\n",
    "            score_dict_lda[cond].append(np.nan)\n",
    "            score_dict_svm[cond].append(np.nan)\n",
    "            accuracy_dict_lda[cond].append(np.nan)\n",
    "            accuracy_dict_svm[cond].append(np.nan)\n",
    "            continue\n",
    "\n",
    "        path = f'epochs\\\\P{p:03d}\\\\'\n",
    "        i = 1\n",
    "        x_combined = []\n",
    "        y_combined = []\n",
    "        trial_data = []\n",
    "\n",
    "        # Initialize window error counters per participant\n",
    "        window_errors_lda_p = {cond: {t: 0 for t in np.arange(-6, 0.001, 0.125) if marker == 1009 else np.arange(-5, 1.001, 0.125)}}\n",
    "        window_errors_svm_p = {cond: {t: 0 for t in np.arange(-6, 0.001, 0.125) if marker == 1009 else np.arange(-5, 1.001, 0.125)}}\n",
    "\n",
    "        while i < 3:\n",
    "            # P13 only has one walking condition\n",
    "            if marker == 1009:\n",
    "                filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_first_{marker}_epo.fif'     # Change to 1029\n",
    "            else:\n",
    "                filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_{marker}_epo.fif'\n",
    "            epochs = mne.read_epochs(path + filename)\n",
    "            epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "\n",
    "            # For 1029: -5, 0.0001; For 1009: -6, -0.999\n",
    "            if marker == 1009:\n",
    "                start_times = np.arange(-6, 0.001, 0.125)\n",
    "                epochs.crop(tmin=-6, tmax=1)\n",
    "            else:\n",
    "                start_times = np.arange(-5, 1.001, 0.125)\n",
    "                epochs.crop(tmin=-5, tmax=2)\n",
    "            epochs.resample(sfreq=10)\n",
    "\n",
    "            ### Loop over all Epochs and create Sliding windows ###\n",
    "            for j in range(len(epochs)):\n",
    "                epoch = mrcp(epochs[j])\n",
    "                # make_fixed_length_epochs can only be applied to raw data so I transform single epochs into raw by using the data and info from it\n",
    "                raw = mne.io.RawArray(epoch.get_data(), epochs.info)\n",
    "                sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "\n",
    "                # Normalizing the features to l2 norm\n",
    "                X = sliding_window.get_data()\n",
    "                X_features = X.reshape(X.shape[0], -1)\n",
    "                norms = np.linalg.norm(X_features, axis=1, keepdims=True)\n",
    "                norms[norms == 0] = 1.0\n",
    "                X_features = X_features / norms\n",
    "\n",
    "                # Constructing the correct labels for y; a sliding window is regarded as pre-movement if more than half of the window is in pre-movement state\n",
    "                y = []\n",
    "                for t in start_times:\n",
    "                    # For 1029: -1.375; For 1009: -2.375\n",
    "                    if marker == 1009:\n",
    "                        if t < -2.375:\n",
    "                            y.append(0)\n",
    "                        elif t > 1:\n",
    "                            y.append(0)\n",
    "                        else:\n",
    "                            y.append(1)\n",
    "                    else:\n",
    "                        if t < -1.375:\n",
    "                            y.append(0)\n",
    "                        elif t > 2:\n",
    "                            y.append(0)\n",
    "                        else:\n",
    "                            y.append(1)\n",
    "                y = np.array(y)\n",
    "\n",
    "                # Aggregating the epoch data\n",
    "                x_combined.append(X_features)\n",
    "                y_combined.append(y)\n",
    "                trial_data.append((X_features, y, start_times))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        # combining the two sessions of a condition\n",
    "        x_combined = np.concatenate(x_combined, axis=0)\n",
    "        y_combined = np.concatenate(y_combined, axis=0)\n",
    "\n",
    "        #initializing the classifiers, CV and scorer\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "        svm = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        f05_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "        # Perform window based classification\n",
    "        scores_lda = cross_val_score(lda, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "        scores_svm = cross_val_score(svm, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "\n",
    "        score_dict_lda[cond].append(scores_lda.mean())\n",
    "        score_dict_svm[cond].append(scores_svm.mean())\n",
    "\n",
    "        ### Start of Accuracy Evaluation ###\n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "        accuracies_lda = []\n",
    "        accuracies_svm = []\n",
    "        fold_all_probs = []\n",
    "        fold_all_times = []\n",
    "        if 'window_errors_lda' not in locals():\n",
    "            window_errors_lda = {cond: {t: 0 for t in start_times} for cond in conditions}\n",
    "        if 'window_errors_svm' not in locals():\n",
    "            window_errors_svm = {cond: {t: 0 for t in start_times} for cond in conditions}\n",
    "\n",
    "        for fold_num, (train_idx, test_idx) in enumerate(kf.split(trial_data)):\n",
    "            # Prepare data\n",
    "            train_trials = [trial_data[i] for i in train_idx]\n",
    "            test_trials = [trial_data[i] for i in test_idx]\n",
    "\n",
    "            X_train = np.concatenate([X for X, y, t in train_trials], axis=0)\n",
    "            y_train = np.concatenate([y for X, y, t in train_trials], axis=0)\n",
    "\n",
    "            # Fit classifiers\n",
    "            lda.fit(X_train, y_train)\n",
    "            svm.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate on test trials\n",
    "            correct_lda = 0\n",
    "            correct_svm = 0\n",
    "\n",
    "            all_probs = []     # Store predicted probs for class 1\n",
    "            all_times = []     # Store time vectors\n",
    "\n",
    "            for X_trial, y_trial, t_trial in test_trials:\n",
    "                y_pred_lda = lda.predict(X_trial)\n",
    "                y_pred_svm = svm.predict(X_trial)\n",
    "                probs = svm.predict_proba(X_trial)[:, 1]\n",
    "                all_probs.append(probs)\n",
    "                all_times.append(t_trial)\n",
    "\n",
    "                ### BEGIN COUNTING ERRORS PER TIME WINDOW ###\n",
    "                for true_label, pred_label, time in zip(y_trial, y_pred_lda, t_trial):\n",
    "                    if true_label != pred_label:\n",
    "                        window_errors_lda_p[cond][time] += 1\n",
    "                for true_label, pred_label, time in zip(y_trial, y_pred_svm, t_trial):\n",
    "                    if true_label != pred_label:\n",
    "                        window_errors_svm_p[cond][time] += 1\n",
    "                ### END COUNTING ERRORS PER TIME WINDOW ###\n",
    "\n",
    "                if marker == 1009:\n",
    "                    if trial_correct_1009(y_trial, y_pred_lda, t_trial):\n",
    "                        correct_lda += 1\n",
    "                    if trial_correct_1009(y_trial, y_pred_svm, t_trial):\n",
    "                        correct_svm += 1\n",
    "                else:\n",
    "                    if trial_correct_1029(y_trial, y_pred_lda, t_trial):\n",
    "                        correct_lda += 1\n",
    "                    if trial_correct_1029(y_trial, y_pred_svm, t_trial):\n",
    "                        correct_svm += 1\n",
    "\n",
    "            fold_accuracy_lda = correct_lda / len(test_trials)\n",
    "            fold_accuracy_svm = correct_svm / len(test_trials)\n",
    "\n",
    "            accuracies_lda.append(fold_accuracy_lda)\n",
    "            accuracies_svm.append(fold_accuracy_svm)\n",
    "\n",
    "\n",
    "\n",
    "        # Store average accuracy over 5 folds\n",
    "        accuracy_dict_lda[cond].append(np.mean(accuracies_lda))\n",
    "        accuracy_dict_svm[cond].append(np.mean(accuracies_svm))\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean LDA F0.5 Score: {scores_lda.mean():.3f} | Accuracy: {np.mean(accuracies_lda):.3f}\")\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean SVM F0.5 Score: {scores_svm.mean():.3f} | Accuracy: {np.mean(accuracies_svm):.3f}\")\n",
    "        print(f\"Participant {p} | LDA CV {accuracies_lda} | SVM CV {accuracies_svm}\")\n",
    "\n",
    "        rows = []\n",
    "        for time in sorted(window_errors_lda_p[cond].keys()):\n",
    "            rows.append({\n",
    "                \"Participant\": p,\n",
    "                \"Condition\": cond,\n",
    "                \"Time\": time,\n",
    "                \"LDA_Errors\": window_errors_lda_p[cond][time],\n",
    "                \"SVM_Errors\": window_errors_svm_p[cond][time]\n",
    "            })\n",
    "\n",
    "        df_participant_errors = pd.DataFrame(rows)\n",
    "        output_dir = f\"results\\\\window_errors\\\\{marker}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        df_participant_errors.to_csv(f\"{output_dir}\\\\P{p:03d}_{cond}_window_errors.csv\", index=False)\n",
    "\n",
    "# Print group means\n",
    "for cond in conditions:\n",
    "    print(f\"{cond} | LDA Mean F0.5 Score: {np.nanmean(score_dict_lda[cond]):.3f} | LDA Accuracy: {np.nanmean(accuracy_dict_lda[cond]):.3f}\")\n",
    "    print(f\"{cond} | SVM Mean F0.5 Score: {np.nanmean(score_dict_svm[cond]):.3f} | SVM Accuracy: {np.nanmean(accuracy_dict_svm[cond]):.3f}\")\n",
    "\n",
    "# Convert results to DataFrame for saving\n",
    "participants = list(range(0, 14))\n",
    "# Exclude participants that were skipped per condition\n",
    "def get_valid_scores(score_dict, cond):\n",
    "    valid_scores = []\n",
    "    for idx, p in enumerate(participants):\n",
    "        if (p in [4]) or (p == 3 and cond == 'Omnideck') or (p == 7 and cond == 'Leaning') or (p == 7 and cond == 'Joystick'):\n",
    "            valid_scores.append(np.nan)\n",
    "        else:\n",
    "            valid_scores.append(score_dict[cond][len(valid_scores)])\n",
    "    return valid_scores\n",
    "# Create list of records (rows)\n",
    "rows = []\n",
    "for cond in conditions:\n",
    "    for i, p in enumerate(participants):\n",
    "        row = {\n",
    "            \"Participant\": p+1,\n",
    "            \"Condition\": cond,\n",
    "            \"LDA_F0.5_Score\": score_dict_lda[cond][i],\n",
    "            \"SVM_F0.5_Score\": score_dict_svm[cond][i],\n",
    "            \"LDA_Accuracy\": accuracy_dict_lda[cond][i],\n",
    "            \"SVM_Accuracy\": accuracy_dict_svm[cond][i]\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Save to CSV\n",
    "if marker == 1009:\n",
    "    df.to_csv(f\"results\\\\classification_results_single_cond_first_{marker}.csv\", index=False)\n",
    "else:\n",
    "    df.to_csv(f\"results\\\\classification_results_single_cond_{marker}.csv\", index=False)\n",
    "print(\"Results saved to classification_results.csv\")\n"
   ],
   "id": "c6fbf31187d02537",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2771854984.py, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[18], line 24\u001B[1;36m\u001B[0m\n\u001B[1;33m    window_errors_lda_p = {cond: {t: 0 for t in np.arange(-6, 0.001, 0.125) if marker == 1009 else np.arange(-5, 1.001, 0.125)}}\u001B[0m\n\u001B[1;37m                                                                                              ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:16:24.395879Z",
     "start_time": "2025-07-22T08:16:24.391782Z"
    }
   },
   "cell_type": "code",
   "source": "#TODO: Make a list with all the time windows and count where missclassifications happen\n",
   "id": "922d8bbd4e9a8245",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.   , -5.875, -5.75 , -5.625, -5.5  , -5.375, -5.25 , -5.125,\n",
       "       -5.   , -4.875, -4.75 , -4.625, -4.5  , -4.375, -4.25 , -4.125,\n",
       "       -4.   , -3.875, -3.75 , -3.625, -3.5  , -3.375, -3.25 , -3.125,\n",
       "       -3.   , -2.875, -2.75 , -2.625, -2.5  , -2.375, -2.25 , -2.125,\n",
       "       -2.   , -1.875, -1.75 , -1.625, -1.5  , -1.375, -1.25 , -1.125,\n",
       "       -1.   , -0.875, -0.75 , -0.625, -0.5  , -0.375, -0.25 , -0.125,\n",
       "        0.   ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T15:51:28.984784Z",
     "start_time": "2025-07-17T15:51:28.981839Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO: Chance level Estimate",
   "id": "c183546c600070e0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Leave one Condition out Transferlearning",
   "id": "ec766717b1ff4bf7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T16:10:48.172200Z",
     "start_time": "2025-07-17T16:04:37.855524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "score_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "score_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "\n",
    "conditions = ['Joystick', 'Leaning', 'Omnideck', 'Walking']\n",
    "participants = list(range(1, 15))\n",
    "excluded = {\n",
    "    (3, 'Omnideck'), (4, 'Joystick'), (7, 'Leaning'), (7, 'Joystick'), (13, 'Walking')\n",
    "}\n",
    "marker = 1029\n",
    "for p in participants:\n",
    "    for test_cond in conditions:\n",
    "        ### Dealing with Missing data ###\n",
    "        if (p, test_cond) in excluded:\n",
    "            score_dict_lda[test_cond].append(np.nan)\n",
    "            score_dict_svm[test_cond].append(np.nan)\n",
    "            accuracy_dict_lda[test_cond].append(np.nan)\n",
    "            accuracy_dict_svm[test_cond].append(np.nan)\n",
    "            continue\n",
    "\n",
    "        path = f'epochs\\\\P{p:03d}\\\\'\n",
    "        x_train, y_train = [], []\n",
    "        x_test, y_test = [], []\n",
    "        test_trials = []\n",
    "\n",
    "        for cond in conditions:\n",
    "            if (p, cond) in excluded:\n",
    "                continue\n",
    "            for i in range(1, 3):\n",
    "                if p == 13 and cond == 'Walking' and i == 2:\n",
    "                    continue\n",
    "\n",
    "                if marker == 1009:\n",
    "                    filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_first_{marker}_epo.fif'\n",
    "                else:\n",
    "                    filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_{marker}_epo.fif'\n",
    "\n",
    "                # If files does not exist\n",
    "                try:\n",
    "                    epochs = mne.read_epochs(path + filename, verbose='error')\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"File {filename} not found\")\n",
    "                    continue\n",
    "\n",
    "                # Arranging the start times correctly based on marker; 1029 is delayed by one second\n",
    "                epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "                if marker == 1009:\n",
    "                    start_times = np.arange(-6, 0.001, 0.125)\n",
    "                    epochs.crop(tmin=-6, tmax=1)\n",
    "                else:\n",
    "                    start_times = np.arange(-5, 1.001, 0.125)\n",
    "                    epochs.crop(tmin=-5, tmax=2)\n",
    "                epochs.resample(sfreq=10)\n",
    "\n",
    "                # Loop through all epochs create the sliding windows and labels\n",
    "                for j in range(len(epochs)):\n",
    "                    epoch = mrcp(epochs[j])\n",
    "                    raw = mne.io.RawArray(epoch.get_data(), epochs.info)\n",
    "                    sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "                    X = sliding_window.get_data()\n",
    "                    X_features = X.reshape(X.shape[0], -1)\n",
    "                    norms = np.linalg.norm(X_features, axis=1, keepdims=True)\n",
    "                    norms[norms == 0] = 1.0\n",
    "                    X_features = X_features / norms\n",
    "\n",
    "                    # cleaner code using list comprehensions\n",
    "                    if marker == 1009:\n",
    "                        y = [1 if -2.375 <= t <= 1 else 0 for t in start_times]\n",
    "                    else:\n",
    "                        y = [1 if -1.375 <= t <= 2 else 0 for t in start_times]\n",
    "                    y = np.array(y)\n",
    "\n",
    "                    # Aggregate the data based on the current test condition\n",
    "                    if cond == test_cond:\n",
    "                        x_test.append(X_features)\n",
    "                        y_test.append(y)\n",
    "                        test_trials.append((X_features, y, start_times))\n",
    "                    else:\n",
    "                        x_train.append(X_features)\n",
    "                        y_train.append(y)\n",
    "\n",
    "        # Deal with missing possible missing conditions if not flagged earlier\n",
    "        if not x_train or not x_test:\n",
    "            score_dict_lda[test_cond].append(np.nan)\n",
    "            score_dict_svm[test_cond].append(np.nan)\n",
    "            accuracy_dict_lda[test_cond].append(np.nan)\n",
    "            accuracy_dict_svm[test_cond].append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Create the test and train data\n",
    "        x_train = np.concatenate(x_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "        x_test_all = np.concatenate(x_test, axis=0)\n",
    "        y_test_all = np.concatenate(y_test, axis=0)\n",
    "\n",
    "        # Initialize Classifiers\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "        svm = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "        # Fit Classifiers\n",
    "        lda.fit(x_train, y_train)\n",
    "        svm.fit(x_train, y_train)\n",
    "\n",
    "        # Predict test set and score based on F0.5-score\n",
    "        y_pred_lda = lda.predict(x_test_all)\n",
    "        y_pred_svm = svm.predict(x_test_all)\n",
    "\n",
    "        f05_lda = fbeta_score(y_test_all, y_pred_lda, beta=0.5)\n",
    "        f05_svm = fbeta_score(y_test_all, y_pred_svm, beta=0.5)\n",
    "\n",
    "        score_dict_lda[test_cond].append(f05_lda)\n",
    "        score_dict_svm[test_cond].append(f05_svm)\n",
    "\n",
    "        # Trial-based accuracy; figured out += True works\n",
    "        correct_lda = 0\n",
    "        correct_svm = 0\n",
    "        for X_trial, y_trial, t_trial in test_trials:\n",
    "            pred_lda = lda.predict(X_trial)\n",
    "            pred_svm = svm.predict(X_trial)\n",
    "            if marker == 1009:\n",
    "                correct_lda += trial_correct_1009(y_trial, pred_lda, t_trial)\n",
    "                correct_svm += trial_correct_1009(y_trial, pred_svm, t_trial)\n",
    "            else:\n",
    "                correct_lda += trial_correct_1029(y_trial, pred_lda, t_trial)\n",
    "                correct_svm += trial_correct_1029(y_trial, pred_svm, t_trial)\n",
    "\n",
    "        total_trials = len(test_trials)\n",
    "        accuracy_dict_lda[test_cond].append(correct_lda / total_trials)\n",
    "        accuracy_dict_svm[test_cond].append(correct_svm / total_trials)\n",
    "\n",
    "        print(f\"Participant {p} | Test: {test_cond} | LDA F0.5: {f05_lda:.3f}, Acc: {correct_lda / total_trials:.3f}\")\n",
    "        print(f\"Participant {p} | Test: {test_cond} | SVM F0.5: {f05_svm:.3f}, Acc: {correct_svm / total_trials:.3f}\")\n",
    "\n",
    "# Group mean results\n",
    "for cond in conditions:\n",
    "    print(f\"{cond} | LDA Mean F0.5: {np.nanmean(score_dict_lda[cond]):.3f}, LDA Acc: {np.nanmean(accuracy_dict_lda[cond]):.3f}\")\n",
    "    print(f\"{cond} | SVM Mean F0.5: {np.nanmean(score_dict_svm[cond]):.3f}, SVM Acc: {np.nanmean(accuracy_dict_svm[cond]):.3f}\")\n",
    "\n",
    "rows = []\n",
    "for i, p in enumerate(participants):\n",
    "    for cond in conditions:\n",
    "        if i < len(score_dict_lda[cond]):\n",
    "            rows.append({\n",
    "                'Participant': p,\n",
    "                'Test_Condition': cond,\n",
    "                'LDA_F0.5': score_dict_lda[cond][i],\n",
    "                'LDA_Accuracy': accuracy_dict_lda[cond][i],\n",
    "                'SVM_F0.5': score_dict_svm[cond][i],\n",
    "                'SVM_Accuracy': accuracy_dict_svm[cond][i]\n",
    "            })\n",
    "\n",
    "### Convert to DataFrame and save ###\n",
    "df = pd.DataFrame(rows)\n",
    "if marker == 1009:\n",
    "    df.to_csv(f\"results\\\\cross_condition_results_first_{marker}.csv\", index=False)\n",
    "else:\n",
    "    df.to_csv(f\"results\\\\cross_condition_results_{marker}.csv\", index=False)\n",
    "print(\"Results saved to 'cross_condition_results_first_1009.csv'\")"
   ],
   "id": "7cb9c2ee5076ea68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant 1 | Test: Joystick | LDA F0.5: 0.518, Acc: 0.324\n",
      "Participant 1 | Test: Joystick | SVM F0.5: 0.592, Acc: 0.189\n",
      "Participant 1 | Test: Leaning | LDA F0.5: 0.386, Acc: 0.053\n",
      "Participant 1 | Test: Leaning | SVM F0.5: 0.389, Acc: 0.026\n",
      "Participant 1 | Test: Omnideck | LDA F0.5: 0.384, Acc: 0.081\n",
      "Participant 1 | Test: Omnideck | SVM F0.5: 0.431, Acc: 0.135\n",
      "Participant 1 | Test: Walking | LDA F0.5: 0.327, Acc: 0.081\n",
      "Participant 1 | Test: Walking | SVM F0.5: 0.388, Acc: 0.135\n",
      "Participant 2 | Test: Joystick | LDA F0.5: 0.325, Acc: 0.237\n",
      "Participant 2 | Test: Joystick | SVM F0.5: 0.322, Acc: 0.105\n",
      "Participant 2 | Test: Leaning | LDA F0.5: 0.386, Acc: 0.132\n",
      "Participant 2 | Test: Leaning | SVM F0.5: 0.342, Acc: 0.053\n",
      "Participant 2 | Test: Omnideck | LDA F0.5: 0.429, Acc: 0.184\n",
      "Participant 2 | Test: Omnideck | SVM F0.5: 0.363, Acc: 0.026\n",
      "Participant 2 | Test: Walking | LDA F0.5: 0.426, Acc: 0.105\n",
      "Participant 2 | Test: Walking | SVM F0.5: 0.417, Acc: 0.105\n",
      "Participant 3 | Test: Joystick | LDA F0.5: 0.469, Acc: 0.184\n",
      "Participant 3 | Test: Joystick | SVM F0.5: 0.522, Acc: 0.184\n",
      "Participant 3 | Test: Leaning | LDA F0.5: 0.577, Acc: 0.026\n",
      "Participant 3 | Test: Leaning | SVM F0.5: 0.537, Acc: 0.158\n",
      "Participant 3 | Test: Walking | LDA F0.5: 0.684, Acc: 0.105\n",
      "Participant 3 | Test: Walking | SVM F0.5: 0.559, Acc: 0.053\n",
      "File sub-P004_ses-Leaning1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Leaning2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Leaning1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Leaning2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Leaning1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Leaning2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Omnideck2_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking1_epochs_1029_epo.fif not found\n",
      "File sub-P004_ses-Walking2_epochs_1029_epo.fif not found\n",
      "Participant 5 | Test: Joystick | LDA F0.5: 0.527, Acc: 0.132\n",
      "Participant 5 | Test: Joystick | SVM F0.5: 0.518, Acc: 0.053\n",
      "Participant 5 | Test: Leaning | LDA F0.5: 0.365, Acc: 0.158\n",
      "Participant 5 | Test: Leaning | SVM F0.5: 0.479, Acc: 0.053\n",
      "Participant 5 | Test: Omnideck | LDA F0.5: 0.524, Acc: 0.132\n",
      "Participant 5 | Test: Omnideck | SVM F0.5: 0.529, Acc: 0.105\n",
      "Participant 5 | Test: Walking | LDA F0.5: 0.462, Acc: 0.184\n",
      "Participant 5 | Test: Walking | SVM F0.5: 0.497, Acc: 0.105\n",
      "Participant 6 | Test: Joystick | LDA F0.5: 0.659, Acc: 0.184\n",
      "Participant 6 | Test: Joystick | SVM F0.5: 0.662, Acc: 0.158\n",
      "Participant 6 | Test: Leaning | LDA F0.5: 0.435, Acc: 0.158\n",
      "Participant 6 | Test: Leaning | SVM F0.5: 0.477, Acc: 0.132\n",
      "Participant 6 | Test: Omnideck | LDA F0.5: 0.593, Acc: 0.105\n",
      "Participant 6 | Test: Omnideck | SVM F0.5: 0.544, Acc: 0.105\n",
      "Participant 6 | Test: Walking | LDA F0.5: 0.347, Acc: 0.158\n",
      "Participant 6 | Test: Walking | SVM F0.5: 0.404, Acc: 0.237\n",
      "Participant 7 | Test: Omnideck | LDA F0.5: 0.376, Acc: 0.079\n",
      "Participant 7 | Test: Omnideck | SVM F0.5: 0.260, Acc: 0.105\n",
      "Participant 7 | Test: Walking | LDA F0.5: 0.521, Acc: 0.054\n",
      "Participant 7 | Test: Walking | SVM F0.5: 0.488, Acc: 0.270\n",
      "Participant 8 | Test: Joystick | LDA F0.5: 0.731, Acc: 0.263\n",
      "Participant 8 | Test: Joystick | SVM F0.5: 0.649, Acc: 0.263\n",
      "Participant 8 | Test: Leaning | LDA F0.5: 0.536, Acc: 0.158\n",
      "Participant 8 | Test: Leaning | SVM F0.5: 0.560, Acc: 0.184\n",
      "Participant 8 | Test: Omnideck | LDA F0.5: 0.502, Acc: 0.053\n",
      "Participant 8 | Test: Omnideck | SVM F0.5: 0.603, Acc: 0.105\n",
      "Participant 8 | Test: Walking | LDA F0.5: 0.636, Acc: 0.237\n",
      "Participant 8 | Test: Walking | SVM F0.5: 0.589, Acc: 0.132\n",
      "Participant 9 | Test: Joystick | LDA F0.5: 0.517, Acc: 0.158\n",
      "Participant 9 | Test: Joystick | SVM F0.5: 0.547, Acc: 0.079\n",
      "Participant 9 | Test: Leaning | LDA F0.5: 0.643, Acc: 0.158\n",
      "Participant 9 | Test: Leaning | SVM F0.5: 0.572, Acc: 0.026\n",
      "Participant 9 | Test: Omnideck | LDA F0.5: 0.654, Acc: 0.263\n",
      "Participant 9 | Test: Omnideck | SVM F0.5: 0.489, Acc: 0.316\n",
      "Participant 9 | Test: Walking | LDA F0.5: 0.680, Acc: 0.237\n",
      "Participant 9 | Test: Walking | SVM F0.5: 0.560, Acc: 0.237\n",
      "Participant 10 | Test: Joystick | LDA F0.5: 0.491, Acc: 0.105\n",
      "Participant 10 | Test: Joystick | SVM F0.5: 0.531, Acc: 0.079\n",
      "Participant 10 | Test: Leaning | LDA F0.5: 0.541, Acc: 0.211\n",
      "Participant 10 | Test: Leaning | SVM F0.5: 0.565, Acc: 0.132\n",
      "Participant 10 | Test: Omnideck | LDA F0.5: 0.498, Acc: 0.289\n",
      "Participant 10 | Test: Omnideck | SVM F0.5: 0.555, Acc: 0.132\n",
      "Participant 10 | Test: Walking | LDA F0.5: 0.565, Acc: 0.132\n",
      "Participant 10 | Test: Walking | SVM F0.5: 0.552, Acc: 0.105\n",
      "Participant 11 | Test: Joystick | LDA F0.5: 0.559, Acc: 0.105\n",
      "Participant 11 | Test: Joystick | SVM F0.5: 0.584, Acc: 0.053\n",
      "Participant 11 | Test: Leaning | LDA F0.5: 0.464, Acc: 0.079\n",
      "Participant 11 | Test: Leaning | SVM F0.5: 0.559, Acc: 0.053\n",
      "Participant 11 | Test: Omnideck | LDA F0.5: 0.626, Acc: 0.184\n",
      "Participant 11 | Test: Omnideck | SVM F0.5: 0.598, Acc: 0.263\n",
      "Participant 11 | Test: Walking | LDA F0.5: 0.663, Acc: 0.237\n",
      "Participant 11 | Test: Walking | SVM F0.5: 0.575, Acc: 0.105\n",
      "Participant 12 | Test: Joystick | LDA F0.5: 0.380, Acc: 0.105\n",
      "Participant 12 | Test: Joystick | SVM F0.5: 0.491, Acc: 0.184\n",
      "Participant 12 | Test: Leaning | LDA F0.5: 0.556, Acc: 0.263\n",
      "Participant 12 | Test: Leaning | SVM F0.5: 0.455, Acc: 0.105\n",
      "Participant 12 | Test: Omnideck | LDA F0.5: 0.312, Acc: 0.158\n",
      "Participant 12 | Test: Omnideck | SVM F0.5: 0.425, Acc: 0.079\n",
      "Participant 12 | Test: Walking | LDA F0.5: 0.398, Acc: 0.026\n",
      "Participant 12 | Test: Walking | SVM F0.5: 0.439, Acc: 0.211\n",
      "Participant 13 | Test: Joystick | LDA F0.5: 0.558, Acc: 0.079\n",
      "Participant 13 | Test: Joystick | SVM F0.5: 0.554, Acc: 0.158\n",
      "Participant 13 | Test: Leaning | LDA F0.5: 0.321, Acc: 0.105\n",
      "Participant 13 | Test: Leaning | SVM F0.5: 0.422, Acc: 0.026\n",
      "Participant 13 | Test: Omnideck | LDA F0.5: 0.561, Acc: 0.237\n",
      "Participant 13 | Test: Omnideck | SVM F0.5: 0.544, Acc: 0.079\n",
      "Participant 14 | Test: Joystick | LDA F0.5: 0.657, Acc: 0.211\n",
      "Participant 14 | Test: Joystick | SVM F0.5: 0.667, Acc: 0.105\n",
      "Participant 14 | Test: Leaning | LDA F0.5: 0.298, Acc: 0.184\n",
      "Participant 14 | Test: Leaning | SVM F0.5: 0.349, Acc: 0.184\n",
      "Participant 14 | Test: Omnideck | LDA F0.5: 0.552, Acc: 0.368\n",
      "Participant 14 | Test: Omnideck | SVM F0.5: 0.558, Acc: 0.237\n",
      "Participant 14 | Test: Walking | LDA F0.5: 0.644, Acc: 0.184\n",
      "Participant 14 | Test: Walking | SVM F0.5: 0.652, Acc: 0.342\n",
      "Joystick | LDA Mean F0.5: 0.533, LDA Acc: 0.174\n",
      "Joystick | SVM Mean F0.5: 0.553, SVM Acc: 0.134\n",
      "Leaning | LDA Mean F0.5: 0.459, LDA Acc: 0.140\n",
      "Leaning | SVM Mean F0.5: 0.475, SVM Acc: 0.094\n",
      "Omnideck | LDA Mean F0.5: 0.501, LDA Acc: 0.178\n",
      "Omnideck | SVM Mean F0.5: 0.492, SVM Acc: 0.141\n",
      "Walking | LDA Mean F0.5: 0.529, LDA Acc: 0.145\n",
      "Walking | SVM Mean F0.5: 0.510, SVM Acc: 0.170\n",
      "Results saved to 'cross_condition_results_first_1009.csv'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Walking --> Omnideck Transfer (and vice versa)",
   "id": "e352851e0a6c75ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T16:11:23.237630Z",
     "start_time": "2025-07-17T16:10:48.205794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transfer learning from training on Omnideck and testing on real walking and the other way round\n",
    "marker = 1029\n",
    "results = []\n",
    "participants = list(range(1, 15))\n",
    "excluded = {\n",
    "    (3, 'Omnideck'), (7, 'Leaning'), (7, 'Joystick'), (13, 'Walking')\n",
    "}\n",
    "\n",
    "for p in participants:\n",
    "    for train_cond, test_cond in [('Walking', 'Omnideck'), ('Omnideck', 'Walking')]:\n",
    "        if (p, train_cond) in excluded or (p, test_cond) in excluded or p == 4:\n",
    "            results.append((p, train_cond, test_cond, np.nan, np.nan, np.nan, np.nan))\n",
    "            continue\n",
    "\n",
    "        path = f'epochs\\\\P{p:03d}\\\\'\n",
    "        x_train, y_train = [], []\n",
    "        x_test, y_test = [], []\n",
    "        test_trials = []\n",
    "\n",
    "        for cond, store in [(train_cond, 'train'), (test_cond, 'test')]:\n",
    "            for i in range(1, 3):\n",
    "                if p == 13 and cond == 'Walking' and i == 2:\n",
    "                    continue\n",
    "                if marker == 1009:\n",
    "                    filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_first_{marker}_autoreject_epo.fif'\n",
    "                else:\n",
    "                    filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_{marker}_autoreject_epo.fif'\n",
    "                try:\n",
    "                    epochs = mne.read_epochs(path + filename, verbose='error')\n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "                epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "\n",
    "                if marker == 1009:\n",
    "                    start_times = np.arange(-6, 0.001, 0.125)\n",
    "                    epochs.crop(tmin=-6, tmax=1)\n",
    "                else:\n",
    "                    start_times = np.arange(-5, 1.001, 0.125)\n",
    "                    epochs.crop(tmin=-5, tmax=2)\n",
    "                epochs.resample(sfreq=10)\n",
    "\n",
    "                for j in range(len(epochs)):\n",
    "                    epoch = mrcp(epochs[j])\n",
    "                    raw = mne.io.RawArray(epoch.get_data(), epochs.info)\n",
    "                    sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "                    X = sliding_window.get_data()\n",
    "                    X_features = X.reshape(X.shape[0], -1)\n",
    "                    norms = np.linalg.norm(X_features, axis=1, keepdims=True)\n",
    "                    norms[norms == 0] = 1.0\n",
    "                    X_features = X_features / norms\n",
    "                    if marker == 1009:\n",
    "                        y = [1 if -2.375 <= t <= 1 else 0 for t in start_times]\n",
    "                    else:\n",
    "                        y = [1 if -1.375 <= t <= 2 else 0 for t in start_times]\n",
    "                    y = np.array(y)\n",
    "\n",
    "                    if store == 'train':\n",
    "                        x_train.append(X_features)\n",
    "                        y_train.append(y)\n",
    "                    else:\n",
    "                        x_test.append(X_features)\n",
    "                        y_test.append(y)\n",
    "                        test_trials.append((X_features, y, start_times))\n",
    "\n",
    "        #if not x_train or not x_test:\n",
    "        #    results.append((p, train_cond, test_cond, np.nan, np.nan, np.nan, np.nan))\n",
    "        #    continue\n",
    "        x_train = np.concatenate(x_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "        x_test_all = np.concatenate(x_test, axis=0)\n",
    "        y_test_all = np.concatenate(y_test, axis=0)\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "        svm = SVC(kernel='rbf', probability=True)\n",
    "        f05 = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "        lda.fit(x_train, y_train)\n",
    "        svm.fit(x_train, y_train)\n",
    "\n",
    "        y_pred_lda = lda.predict(x_test_all)\n",
    "        y_pred_svm = svm.predict(x_test_all)\n",
    "\n",
    "        f05_lda = fbeta_score(y_test_all, y_pred_lda, beta=0.5)\n",
    "        f05_svm = fbeta_score(y_test_all, y_pred_svm, beta=0.5)\n",
    "\n",
    "        # Trial-based accuracy\n",
    "        correct_lda = 0\n",
    "        correct_svm = 0\n",
    "        for X_trial, y_trial, t_trial in test_trials:\n",
    "            pred_lda = lda.predict(X_trial)\n",
    "            pred_svm = svm.predict(X_trial)\n",
    "            if marker == 1009:\n",
    "                correct_lda += trial_correct_1009(y_trial, pred_lda, t_trial)\n",
    "                correct_svm += trial_correct_1009(y_trial, pred_svm, t_trial)\n",
    "            else:\n",
    "                correct_lda += trial_correct_1029(y_trial, pred_lda, t_trial)\n",
    "                correct_svm += trial_correct_1029(y_trial, pred_svm, t_trial)\n",
    "\n",
    "        total_trials = len(test_trials)\n",
    "        acc_lda = correct_lda / total_trials\n",
    "        acc_svm = correct_svm / total_trials\n",
    "\n",
    "        results.append((p, train_cond, test_cond, f05_lda, acc_lda, f05_svm, acc_svm))\n",
    "\n",
    "        print(f\"P{p:02d} | Train: {train_cond} → Test: {test_cond} | \"\n",
    "              f\"LDA F0.5: {f05_lda:.3f}, Acc: {acc_lda:.3f} | \"\n",
    "              f\"SVM F0.5: {f05_svm:.3f}, Acc: {acc_svm:.3f}\")\n",
    "\n",
    "# Optional: print group means\n",
    "for direction in [('Walking', 'Omnideck'), ('Omnideck', 'Walking')]:\n",
    "    f05_lda_all = [r[3] for r in results if (r[1], r[2]) == direction and not np.isnan(r[3])]\n",
    "    acc_lda_all = [r[4] for r in results if (r[1], r[2]) == direction and not np.isnan(r[4])]\n",
    "    f05_svm_all = [r[5] for r in results if (r[1], r[2]) == direction and not np.isnan(r[5])]\n",
    "    acc_svm_all = [r[6] for r in results if (r[1], r[2]) == direction and not np.isnan(r[6])]\n",
    "\n",
    "    print(f\"\\nTrain: {direction[0]} → Test: {direction[1]}\")\n",
    "    print(f\"LDA  Mean F0.5: {np.mean(f05_lda_all):.3f} | Mean Accuracy: {np.mean(acc_lda_all):.3f}\")\n",
    "    print(f\"SVM  Mean F0.5: {np.mean(f05_svm_all):.3f} | Mean Accuracy: {np.mean(acc_svm_all):.3f}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_results = pd.DataFrame(results, columns=[\n",
    "    'Participant', 'Train_Condition', 'Test_Condition',\n",
    "    'LDA_F0.5', 'LDA_Accuracy', 'SVM_F0.5', 'SVM_Accuracy'\n",
    "])\n",
    "\n",
    "# Save to CSV\n",
    "if marker == 1009:\n",
    "    df_results.to_csv(f'results\\\\transfer_learning_omideck_walking_first_{marker}_results.csv', index=False)\n",
    "else:\n",
    "    df_results.to_csv(f'results\\\\transfer_learning_omideck_walking_{marker}_results.csv', index=False)\n",
    "print(\"Results saved to 'transfer_learning_results.csv'\")\n"
   ],
   "id": "e099c8906bf26aa6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01 | Train: Walking → Test: Omnideck | LDA F0.5: 0.497, Acc: 0.167 | SVM F0.5: 0.486, Acc: 0.083\n",
      "P01 | Train: Omnideck → Test: Walking | LDA F0.5: 0.561, Acc: 0.088 | SVM F0.5: 0.575, Acc: 0.324\n",
      "P02 | Train: Walking → Test: Omnideck | LDA F0.5: 0.469, Acc: 0.032 | SVM F0.5: 0.422, Acc: 0.226\n",
      "P02 | Train: Omnideck → Test: Walking | LDA F0.5: 0.526, Acc: 0.030 | SVM F0.5: 0.542, Acc: 0.152\n",
      "P05 | Train: Walking → Test: Omnideck | LDA F0.5: 0.415, Acc: 0.162 | SVM F0.5: 0.454, Acc: 0.135\n",
      "P05 | Train: Omnideck → Test: Walking | LDA F0.5: 0.460, Acc: 0.027 | SVM F0.5: 0.478, Acc: 0.081\n",
      "P06 | Train: Walking → Test: Omnideck | LDA F0.5: 0.450, Acc: 0.100 | SVM F0.5: 0.404, Acc: 0.133\n",
      "P06 | Train: Omnideck → Test: Walking | LDA F0.5: 0.448, Acc: 0.088 | SVM F0.5: 0.472, Acc: 0.147\n",
      "P07 | Train: Walking → Test: Omnideck | LDA F0.5: 0.573, Acc: 0.235 | SVM F0.5: 0.600, Acc: 0.382\n",
      "P07 | Train: Omnideck → Test: Walking | LDA F0.5: 0.551, Acc: 0.132 | SVM F0.5: 0.552, Acc: 0.132\n",
      "P08 | Train: Walking → Test: Omnideck | LDA F0.5: 0.511, Acc: 0.114 | SVM F0.5: 0.541, Acc: 0.171\n",
      "P08 | Train: Omnideck → Test: Walking | LDA F0.5: 0.591, Acc: 0.161 | SVM F0.5: 0.570, Acc: 0.129\n",
      "P09 | Train: Walking → Test: Omnideck | LDA F0.5: 0.740, Acc: 0.400 | SVM F0.5: 0.672, Acc: 0.267\n",
      "P09 | Train: Omnideck → Test: Walking | LDA F0.5: 0.675, Acc: 0.132 | SVM F0.5: 0.659, Acc: 0.158\n",
      "P10 | Train: Walking → Test: Omnideck | LDA F0.5: 0.447, Acc: 0.000 | SVM F0.5: 0.470, Acc: 0.138\n",
      "P10 | Train: Omnideck → Test: Walking | LDA F0.5: 0.474, Acc: 0.108 | SVM F0.5: 0.479, Acc: 0.081\n",
      "P11 | Train: Walking → Test: Omnideck | LDA F0.5: 0.574, Acc: 0.071 | SVM F0.5: 0.499, Acc: 0.250\n",
      "P11 | Train: Omnideck → Test: Walking | LDA F0.5: 0.644, Acc: 0.027 | SVM F0.5: 0.654, Acc: 0.351\n",
      "P12 | Train: Walking → Test: Omnideck | LDA F0.5: 0.481, Acc: 0.250 | SVM F0.5: 0.580, Acc: 0.000\n",
      "P12 | Train: Omnideck → Test: Walking | LDA F0.5: 0.470, Acc: 0.033 | SVM F0.5: 0.436, Acc: 0.167\n",
      "P14 | Train: Walking → Test: Omnideck | LDA F0.5: 0.397, Acc: 0.263 | SVM F0.5: 0.553, Acc: 0.211\n",
      "P14 | Train: Omnideck → Test: Walking | LDA F0.5: 0.571, Acc: 0.000 | SVM F0.5: 0.534, Acc: 0.132\n",
      "\n",
      "Train: Walking → Test: Omnideck\n",
      "LDA  Mean F0.5: 0.505 | Mean Accuracy: 0.163\n",
      "SVM  Mean F0.5: 0.516 | Mean Accuracy: 0.182\n",
      "\n",
      "Train: Omnideck → Test: Walking\n",
      "LDA  Mean F0.5: 0.543 | Mean Accuracy: 0.075\n",
      "SVM  Mean F0.5: 0.541 | Mean Accuracy: 0.168\n",
      "Results saved to 'transfer_learning_results.csv'\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf13d9cbe44cecf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7a5b6a14d3d89e14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c25f44f7a99dbcc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d6cece95ada04e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Leftover Code from Cleanup",
   "id": "e6a87b050f931d44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Make i a function with a parameter that can be 'trial', 'condition', 'subject' or 'global' that runs the classification or just assembles the data in given the scope\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "from sklearn.svm import SVC\n",
    "score_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "score_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "conditions = ['Joystick', 'Leaning', 'Omnideck', 'Walking']\n",
    "for cond in conditions:\n",
    "    for p in range(1,15):\n",
    "        if p == 4 or p == 7 or p == 13:\n",
    "            score_dict_lda[cond].append(np.nan)\n",
    "            score_dict_svm[cond].append(np.nan)\n",
    "            continue\n",
    "        if p == 3 and cond == 'Omnideck':\n",
    "            score_dict_lda[cond].append(np.nan)\n",
    "            score_dict_svm[cond].append(np.nan)\n",
    "            continue\n",
    "        path = f'epochs\\\\P{p:03d}\\\\'\n",
    "        i = 1\n",
    "        while i < 3:\n",
    "            filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_1029_epo.fif'\n",
    "            epochs = mne.read_epochs(path+filename)\n",
    "            epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "            ar = AutoReject(n_jobs=8, verbose=False)\n",
    "            epochs = ar.fit_transform(epochs)\n",
    "            start_times = np.arange(-6, 0.001, 0.125)\n",
    "            nr_epochs = len(epochs)\n",
    "            epochs.crop(tmin=-6, tmax=1)\n",
    "            epochs.resample(sfreq=10)\n",
    "\n",
    "            for j in range(len(epochs)):\n",
    "                epoch = mrcp(epochs[j])\n",
    "                raw = mne.io.RawArray(epoch.get_data(), epochs.info)\n",
    "                sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "                X = sliding_window.get_data()\n",
    "                X_features = X.reshape(X.shape[0], -1)\n",
    "                norms = np.linalg.norm(X_features, axis=1, keepdims=True)\n",
    "                norms[norms == 0] = 1.0  # prevent division by zero\n",
    "                X_features = X_features / norms\n",
    "                y = []\n",
    "                for t in start_times:\n",
    "                    if t < -0.5:\n",
    "                        y.append(0)\n",
    "                    elif t > 1:\n",
    "                        y.append(0)\n",
    "                    else:\n",
    "                        y.append(1)\n",
    "                y = np.array(y)\n",
    "                if i == 1 and j == 0:\n",
    "                    x_combined = X_features\n",
    "                    y_combined = y\n",
    "                else:\n",
    "                    x_combined = np.concatenate([x_combined, X_features], axis=0)\n",
    "                    y_combined = np.concatenate([y_combined, y], axis=0)\n",
    "            i += 1\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "        svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "        # Stratified 5-fold cross-validation\n",
    "        cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "        f05_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "        # Cross-validation scoring (you can change 'accuracy' to 'roc_auc', etc.)\n",
    "        scores_lda = cross_val_score(lda, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "        scores_svm = cross_val_score(svm, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "        score_dict_lda[cond].append(scores_lda.mean())\n",
    "        score_dict_svm[cond].append(scores_svm.mean())\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean LDA F0.5 Score:\", scores_lda.mean())\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean SVM F0.5 Score:\", scores_svm.mean())\n",
    "for cond in conditions:\n",
    "    print(f\"{cond} Mean F0.5 Score:\", np.nanmean(np.array(score_dict_lda[cond])))\n",
    "    print(f\"{cond} Mean F0.5 Score:\", np.nanmean(np.array(score_dict_svm[cond])))\n"
   ],
   "id": "bfaa846c58200971"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import mne\n",
    "from autoreject import AutoReject\n",
    "\n",
    "score_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "score_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_lda = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "accuracy_dict_svm = {'Joystick': [], 'Leaning':[], 'Omnideck':[], 'Walking':[]}\n",
    "\n",
    "conditions = ['Joystick', 'Leaning', 'Omnideck', 'Walking']\n",
    "for cond in conditions:\n",
    "    for p in range(1, 15):\n",
    "        if p in [4] or (p == 7 and cond == 'Leaning') or (p == 7 and cond == 'Joystick'):\n",
    "            score_dict_lda[cond].append(np.nan)\n",
    "            score_dict_svm[cond].append(np.nan)\n",
    "            accuracy_dict_lda[cond].append(np.nan)\n",
    "            accuracy_dict_svm[cond].append(np.nan)\n",
    "            continue\n",
    "\n",
    "        path = f'epochs\\\\P{p:03d}\\\\'\n",
    "        i = 1\n",
    "        x_combined = []\n",
    "        y_combined = []\n",
    "        trial_data = []\n",
    "\n",
    "        while i < 3:\n",
    "            # P13 only has one walking condition\n",
    "            if (p == 13 and cond == 'Walking' and i == 2) or (p == 3 and cond == 'Omnideck' and i == 2):\n",
    "                i+=1\n",
    "                continue\n",
    "            filename = f'sub-P{p:03d}_ses-{cond}{i}_epochs_first_1009_epo.fif'      # Change to 1029\n",
    "            epochs = mne.read_epochs(path + filename)\n",
    "            epochs = epochs.pick(['F3', 'Fz', 'F4', 'FC1', 'FCz', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2'])\n",
    "            ar = AutoReject(n_jobs=8, verbose=False)\n",
    "            epochs = ar.fit_transform(epochs)\n",
    "            # For 1029: -5, 0.0001; For 1009: -6, -0.999\n",
    "            start_times = np.arange(-6, -0.999, 0.125)\n",
    "            epochs.crop(tmin=-6, tmax=0)\n",
    "            epochs.resample(sfreq=10)\n",
    "\n",
    "            for j in range(len(epochs)):\n",
    "                epoch = mrcp(epochs[j])\n",
    "                raw = mne.io.RawArray(epoch.get_data(), epochs.info)\n",
    "                sliding_window = mne.make_fixed_length_epochs(raw, duration=1, overlap=0.875)\n",
    "                X = sliding_window.get_data()\n",
    "                X_features = X.reshape(X.shape[0], -1)\n",
    "                norms = np.linalg.norm(X_features, axis=1, keepdims=True)\n",
    "                norms[norms == 0] = 1.0\n",
    "                X_features = X_features / norms\n",
    "                y = []\n",
    "                for t in start_times:\n",
    "                    # For 1029: -0.875; For 1009: -1.87\n",
    "                    if t < -1.875:\n",
    "                        y.append(0)\n",
    "                    elif t > 0:\n",
    "                        y.append(0)\n",
    "                    else:\n",
    "                        y.append(1)\n",
    "                y = np.array(y)\n",
    "\n",
    "                x_combined.append(X_features)\n",
    "                y_combined.append(y)\n",
    "                trial_data.append((X_features, y, start_times))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        x_combined = np.concatenate(x_combined, axis=0)\n",
    "        y_combined = np.concatenate(y_combined, axis=0)\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "        svm = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        f05_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "        scores_lda = cross_val_score(lda, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "        scores_svm = cross_val_score(svm, x_combined, y_combined, cv=cv, scoring=f05_scorer)\n",
    "\n",
    "        score_dict_lda[cond].append(scores_lda.mean())\n",
    "        score_dict_svm[cond].append(scores_svm.mean())\n",
    "\n",
    "        # Fit classifiers for trial-wise accuracy\n",
    "        lda.fit(x_combined, y_combined)\n",
    "        svm.fit(x_combined, y_combined)\n",
    "\n",
    "        correct_trials_lda = 0\n",
    "        correct_trials_svm = 0\n",
    "\n",
    "        for X_trial, y_trial, t_trial in trial_data:\n",
    "            y_pred_lda = lda.predict(X_trial)\n",
    "            y_pred_svm = svm.predict(X_trial)\n",
    "\n",
    "            # Accuracy\n",
    "            if trial_correct(y_trial, y_pred_lda, t_trial):\n",
    "                correct_trials_lda += 1\n",
    "            if trial_correct(y_trial, y_pred_svm, t_trial):\n",
    "                correct_trials_svm += 1\n",
    "\n",
    "        total_trials = len(trial_data)\n",
    "        accuracy_dict_lda[cond].append(correct_trials_lda / total_trials)\n",
    "        accuracy_dict_svm[cond].append(correct_trials_svm / total_trials)\n",
    "\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean LDA F0.5 Score: {scores_lda.mean():.3f} | Accuracy: {correct_trials_lda / total_trials:.3f}\")\n",
    "        print(f\"Participant {p} | Condition {cond} | Mean SVM F0.5 Score: {scores_svm.mean():.3f} | Accuracy: {correct_trials_svm / total_trials:.3f}\")\n",
    "\n",
    "# Print group means\n",
    "for cond in conditions:\n",
    "    print(f\"{cond} | LDA Mean F0.5 Score: {np.nanmean(score_dict_lda[cond]):.3f} | LDA Accuracy: {np.nanmean(accuracy_dict_lda[cond]):.3f}\")\n",
    "    print(f\"{cond} | SVM Mean F0.5 Score: {np.nanmean(score_dict_svm[cond]):.3f} | SVM Accuracy: {np.nanmean(accuracy_dict_svm[cond]):.3f}\")\n"
   ],
   "id": "b6c181852c55a46e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
